import io, csv
import numpy as np
import pandas as pd
from scipy.signal import butter, filtfilt

# ===== è‡ªå‹•è¨ˆç®— FS =====
def calculate_fs_from_csv(file_path: str) -> float:
    """
    çµ±è¨ˆCSVä¸­æ’é™¤é ­å°¾å¾Œ,ç©©å®šå€çš„æœ€ä½å¹€æ•¸ä½œç‚ºFS
    """
    df = pd.read_csv(file_path)
    df = df[df["state"] == "MAINTAINING"]

    if len(df) < 2:
        return 10.0  # é è¨­å€¼

    t = pd.to_numeric(df["time_seconds"], errors="coerce").to_numpy()
    t = t[np.isfinite(t)]

    if len(t) < 2:
        return 10.0

    # çµ±è¨ˆæ¯ç§’çš„å¹€æ•¸
    sec_counts = {}
    for ti in t:
        sec = int(ti)
        sec_counts[sec] = sec_counts.get(sec, 0) + 1

    # æ’é™¤é ­å°¾
    all_secs = sorted(sec_counts.keys())
    if len(all_secs) <= 2:
        # å¤ªçŸ­å°±ç”¨å…¨éƒ¨
        stable_counts = list(sec_counts.values())
    else:
        # æ’é™¤ç¬¬ä¸€ç§’å’Œæœ€å¾Œä¸€ç§’
        stable_secs = all_secs[1:-1]
        stable_counts = [sec_counts[s] for s in stable_secs]

    if not stable_counts:
        return 10.0

    # å–ç©©å®šå€çš„æœ€ä½å¹€æ•¸
    min_fps = min(stable_counts)
    print(f"ğŸ“Š è‡ªå‹•è¨ˆç®— FS = {min_fps} (ç©©å®šå€æœ€ä½å¹€æ•¸)")
    return float(min_fps)

# ===== åˆ¤æ–· nosepeak_direction çš„ä¸»è¦ç‹€æ…‹ =====
def get_dominant_nosepeak_direction(file_path: str) -> str:
    """
    åªçœ‹æ ¡æ­£éšæ®µ (CALIBRATING) å€’æ•¸å…©ç§’çš„ nosepeak_direction
    """
    df = pd.read_csv(file_path)
    df_calib = df[df["state"] == "CALIBRATING"]

    if len(df_calib) == 0:
        print("âš ï¸  æ‰¾ä¸åˆ° CALIBRATING éšæ®µ,é è¨­ä½¿ç”¨ T")
        return "T"

    if "nosepeak_direction" not in df.columns:
        print("âš ï¸  æ‰¾ä¸åˆ° nosepeak_direction æ¬„ä½,é è¨­ä½¿ç”¨ T")
        return "T"

    # å–æ ¡æ­£éšæ®µçš„æœ€å¾Œå…©ç§’
    t_calib = pd.to_numeric(df_calib["time_seconds"], errors="coerce").to_numpy()
    t_calib = t_calib[np.isfinite(t_calib)]

    if len(t_calib) == 0:
        print("âš ï¸  æ ¡æ­£éšæ®µæ™‚é–“ç•°å¸¸,é è¨­ä½¿ç”¨ T")
        return "T"

    max_time = t_calib.max()
    threshold = max_time - 2.0  # å€’æ•¸å…©ç§’

    # ç¯©é¸å€’æ•¸å…©ç§’çš„è³‡æ–™
    df_last2sec = df_calib[pd.to_numeric(df_calib["time_seconds"], errors="coerce") >= threshold]

    if len(df_last2sec) == 0:
        print("âš ï¸  å€’æ•¸å…©ç§’æ²’æœ‰è³‡æ–™,é è¨­ä½¿ç”¨ T")
        return "T"

    # çµ±è¨ˆ T å’Œ F
    counts = df_last2sec["nosepeak_direction"].value_counts().to_dict()
    t_count = counts.get("T", 0)
    f_count = counts.get("F", 0)

    dominant = "T" if t_count >= f_count else "F"
    print(f"ğŸ“Œ æ ¡æ­£å€’æ•¸2ç§’: T={t_count}, F={f_count} â†’ ä½¿ç”¨ {dominant}")
    return dominant

# ===== åƒæ•¸ =====
CUTOFF = 0.8
ORDER = 4

# ===== ä½é€šæ¿¾æ³¢å™¨ =====
def lowpass_filter(x, fs, cutoff=CUTOFF, order=ORDER):
    b, a = butter(order, cutoff / (fs / 2), btype='low')
    y = filtfilt(b, a, x)
    return y

# ===== ç§»å‹•å¹³å‡ï¼ˆåŸºç·šä¼°è¨ˆï¼‰=====
def moving_average(x, win_samples):
    if win_samples < 1:
        win_samples = 1
    kernel = np.ones(win_samples) / win_samples
    pad_width = win_samples // 2
    x_padded = np.pad(x, pad_width, mode='edge')
    baseline_full = np.convolve(x_padded, kernel, mode='same')
    baseline = baseline_full[pad_width:-pad_width]
    return baseline

# ===== é›¶äº¤å‰æª¢æ¸¬ =====
def zero_crossings(x, t, deadband=0.0, min_interval=10):
    crossings_all, crossings_up, crossings_down = [], [], []
    last_idx = -min_interval
    for i in range(1, len(x)):
        if np.isnan(x[i-1]) or np.isnan(x[i]):
            continue
        # è²  -> æ­£
        if x[i-1] < 0 and x[i] >= 0 and abs(x[i]) > deadband:
            if i - last_idx >= min_interval:
                crossings_all.append(i)
                crossings_up.append(i)
                last_idx = i
        # æ­£ -> è² 
        elif x[i-1] > 0 and x[i] <= 0 and abs(x[i]) > deadband:
            if i - last_idx >= min_interval:
                crossings_all.append(i)
                crossings_down.append(i)
                last_idx = i
    return crossings_all, crossings_up, crossings_down

# ===== å‹•ä½œç¯©é¸ =====
def filter_actions(segments, min_duration=0.5, min_gap=0.5):
    actions = []
    last_end = -1e9
    for seg in segments:
        if seg["duration"] < min_duration:
            continue
        if seg["start_time"] - last_end < min_gap:
            continue
        actions.append(seg)
        last_end = seg["end_time"]
    return actions

# ===== ä¸»æµç¨‹ =====
def analyze_csv(file_path: str) -> dict:
    """
    è®€å– CSVï¼Œè‡ªå‹•è¨ˆç®— FSï¼Œæ ¹æ“š nosepeak_direction é¸æ“‡æ­£/è² åŠé€±
    """
    try:
        # 1. è‡ªå‹•è¨ˆç®— FS
        fs = calculate_fs_from_csv(file_path)

        # 2. åˆ¤æ–· nosepeak_direction (åªçœ‹æ ¡æ­£éšæ®µå€’æ•¸2ç§’)
        dominant_direction = get_dominant_nosepeak_direction(file_path)

        # 3. è®€å–æ•¸æ“š
        with open(file_path, "r", encoding="utf-8") as f:
            df = pd.DataFrame(csv.DictReader(f))
        lowmap = {str(c).strip().lower(): c for c in df.columns if c is not None}

        # æª¢æŸ¥å¿…è¦æ¬„ä½
        if "time_seconds" not in lowmap or "state" not in lowmap or "outer_mouth_z_avg" not in lowmap:
            return {"status": "ERROR", "error": "ç¼ºå°‘å¿…è¦æ¬„ä½"}

        # åªä¿ç•™ MAINTAINING
        df = df[df[lowmap["state"]] == "MAINTAINING"]

        # æ•¸æ“šè½‰ numpy
        t_raw = pd.to_numeric(df[lowmap["time_seconds"]], errors="coerce").to_numpy()
        r_raw = pd.to_numeric(df[lowmap["outer_mouth_z_avg"]], errors="coerce").to_numpy()
        m = np.isfinite(t_raw) & np.isfinite(r_raw)
        t, r = t_raw[m], r_raw[m]

        if len(t) < 2:
            return {"status": "OK", "action_count": 0, "total_action_time": 0.0,
                    "breakpoints": [], "segments": [], "debug": {"note": "insufficient data"}}

        # 4. ä½é€š
        r_filt = lowpass_filter(r, fs=fs, cutoff=CUTOFF, order=ORDER)

        # 5. åŸºç·šæ‰£é™¤
        win = int(4.0 * fs)
        baseline = moving_average(r_filt, win)
        r_detrend = r_filt - baseline

        # 6. é›¶äº¤å‰
        deadband = 0.001 * float(np.std(r_detrend)) if np.std(r_detrend) > 0 else 0.0
        min_interval = int(0.2 * fs)
        zc_all, zc_up, zc_down = zero_crossings(r_detrend, t, deadband=deadband, min_interval=min_interval)

        # 7. å»º segmentsï¼Œæ ¹æ“š nosepeak_direction é¸æ“‡æ­£/è² åŠé€±
        segments = []
        if len(zc_all) >= 2:
            for i, (s, e) in enumerate(zip(zc_all[:-1], zc_all[1:])):
                st, ed = float(t[s]), float(t[e])
                dur = round(ed - st, 3)

                avg_val = np.mean(r_detrend[s:e])

                # T: å–è² åŠé€± (å˜´å·´å¾€å‰, Zè®Šå°)
                # F: å–æ­£åŠé€± (å˜´å·´å¾€å‰, Zè®Šå¤§)
                if dominant_direction == "T":
                    if avg_val < 0:
                        segments.append({
                            "index": i,
                            "start_time": round(st, 3),
                            "end_time": round(ed, 3),
                            "duration": dur
                        })
                else:  # F
                    if avg_val > 0:
                        segments.append({
                            "index": i,
                            "start_time": round(st, 3),
                            "end_time": round(ed, 3),
                            "duration": dur
                        })

        # 8. ç¯©é¸å‹•ä½œ
        actions = filter_actions(segments, min_duration=0.5, min_gap=0.5)

        breakpoints = [seg["end_time"] for seg in segments]
        total_action_time = round(sum(seg["duration"] for seg in actions), 3)

        return {
            "status": "OK",
            "action_count": len(actions),
            "total_action_time": total_action_time,
            "breakpoints": breakpoints,
            "segments": segments,
            "debug": {
                "fs_hz": fs,
                "cutoff": CUTOFF,
                "order": ORDER,
                "nosepeak_direction": dominant_direction,
                "zc_all": len(zc_all),
                "zc_up": len(zc_up),
                "zc_down": len(zc_down),
                "deadband": round(deadband, 6),
                "min_interval": min_interval
            }
        }
    except Exception as e:
        import traceback
        return {"status": "ERROR", "error": str(e), "traceback": traceback.format_exc()}


# ===== æ¸¬è©¦ =====
if __name__ == "__main__":
    file_path = "FaceTraining_POUT_LIPS_20251023_103227.csv"
    result = analyze_csv(file_path)
    print("\nçµæœ:")
    print(f"å‹•ä½œæ•¸: {result.get('action_count', 0)}")
    print(f"ç¸½å‹•ä½œæ™‚é–“: {result.get('total_action_time', 0)}")
    print(f"æ–·é»: {result.get('breakpoints', [])}")
    print(f"\nDebug: {result.get('debug', {})}")