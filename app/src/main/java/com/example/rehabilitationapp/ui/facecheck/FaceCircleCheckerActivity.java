package com.example.rehabilitationapp.ui.facecheck;

import android.Manifest;
import android.content.Intent;
import android.content.pm.PackageManager;
import android.graphics.Bitmap;
import android.graphics.BitmapFactory;
import android.graphics.ImageFormat;
import android.graphics.Matrix;
import android.graphics.Rect;
import android.graphics.YuvImage;
import android.os.Bundle;
import android.os.Handler;
import android.os.Looper;
import android.util.Log;
import android.widget.ProgressBar;
import android.widget.TextView;
import android.widget.Toast;

import androidx.annotation.NonNull;
import androidx.appcompat.app.AppCompatActivity;
import androidx.camera.core.CameraSelector;
import androidx.camera.core.ImageAnalysis;
import androidx.camera.core.ImageProxy;
import androidx.camera.core.Preview;
import androidx.camera.lifecycle.ProcessCameraProvider;
import androidx.camera.view.PreviewView;
// ğŸ¥ å½±ç‰‡éŒ„è£½åŠŸèƒ½
import androidx.camera.video.Recorder;
import androidx.camera.video.Recording;
import androidx.camera.video.VideoCapture;
import androidx.camera.video.VideoRecordEvent;
import androidx.camera.video.FileOutputOptions;
import androidx.camera.video.Quality;
import androidx.camera.video.QualitySelector;

import androidx.core.app.ActivityCompat;
import androidx.core.content.ContextCompat;

import com.example.rehabilitationapp.R;
import com.example.rehabilitationapp.data.AppDatabase;
import com.example.rehabilitationapp.ui.analysis.CSVMotioner;
import com.example.rehabilitationapp.ui.results.AnalysisResultActivity;
import com.example.rehabilitationapp.ui.analysis.CSVPeakAnalyzer;
import com.example.rehabilitationapp.ui.results.TrainingResultActivity;
import com.google.common.util.concurrent.ListenableFuture;
import com.google.mediapipe.framework.image.BitmapImageBuilder;
import com.google.mediapipe.framework.image.MPImage;
import com.google.mediapipe.tasks.core.BaseOptions;
import com.google.mediapipe.tasks.vision.core.RunningMode;
import com.google.mediapipe.tasks.vision.facelandmarker.FaceLandmarker;
import com.google.mediapipe.tasks.vision.facelandmarker.FaceLandmarkerResult;

import java.io.File;
import java.io.ByteArrayOutputStream;
import java.nio.ByteBuffer;
import java.util.Locale;
import java.text.SimpleDateFormat;
import java.util.Arrays;
import java.util.Date;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;
import okhttp3.MediaType;
import okhttp3.OkHttpClient;
import okhttp3.Request;
import okhttp3.RequestBody;
import okhttp3.Response;

import com.example.rehabilitationapp.data.model.User;
import com.example.rehabilitationapp.data.dao.UserDao;
import com.example.rehabilitationapp.data.dao.TrainingHistoryDao;
import com.example.rehabilitationapp.data.model.TrainingHistory;
import android.content.SharedPreferences;



//å…‰æµ
import org.json.JSONArray;
import org.opencv.android.OpenCVLoader;
import org.opencv.core.Point;
//æœ¬ç‰©ä»¶WorkFlowå¯åˆ†ç‚ºåµå´æµèˆ‡é¡¯ç¤º(æ™‚é–“è®€ç§’)æµ
public class FaceCircleCheckerActivity extends AppCompatActivity {
    //<===========ã€Debug&Logã€‘========
    private static final String TAG = "FaceCircleChecker";
    private static final String TAG_2 = "FaceChecker_2";
    private static final String TAG_3 = "FaceCheck_video";
    //===========ã€Debug&Logã€‘========>

    //<=======ã€THREADæ——æ¨™ã€‘===============
    // finalè™•ç†åŸ·è¡Œç·’ï¼Œå¾…ç¾æœ‰Threadè‡ªè¡Œå®Œæˆå¾Œå†é—œé–‰
    private volatile boolean isStopping = false; //ç”Ÿå‘½é€±æœŸonDestroyæ™‚ï¼Œæœƒæ”¹ç‚ºfalse
    // è®“æäº¤ä»»å‹™å‰éƒ½èƒ½å®ˆé–€ï¼Œä¾‹å¦‚åœ¨ handleCheeksMode()ï¼Œè®“æ–¹æ³•å…¥å£åœæ­¢ç¹¼çºŒé‹ä½œï¼š
    private boolean shouldAcceptNewFrames() { return !isStopping; }
    //<=======ã€THREADæ——æ¨™ã€‘===============>


    //<=========ã€ç›¸æ©Ÿæ¬Šé™ç”¨ã€‘==========
    // ç›¸æ©Ÿæ¬Šé™ç”¨
    private static final int PERMISSION_REQUEST_CODE = 123;
    // android.camera.core ç›¸æ©Ÿç®¡ç†
    private PreviewView cameraView;
    private ProcessCameraProvider cameraProvider;
    private boolean trainingStarted = false; // é¿å…é‡è¤‡å•Ÿå‹•
    //=========ã€ç›¸æ©Ÿæ¬Šé™ç”¨ã€‘==========>


    //<=========ã€å½±ç‰‡éŒ„è£½ã€‘==========
    private static final boolean ENABLE_VIDEO_RECORDING = true; // â† æ”¹ false å°±é—œé–‰éŒ„å½±
    private VideoCapture<Recorder> videoCapture;
    private Recording currentRecording;
    private String videoFilePath;
    //<=========ã€å½±ç‰‡éŒ„è£½ã€‘==========>


    //<=========ã€åŸ·è¡Œç·’ç®¡ç†ã€‘==========
    private ExecutorService cameraExecutor;
    private ExecutorService yoloExecutor;
    // ä¸»åŸ·è¡Œç·’ handler èˆ‡è¨ˆæ™‚ä»»å‹™
    private Handler mainHandler;
    private Runnable calibrationTimer;
    private Runnable maintainTimer;
    private Runnable progressUpdater;
    //===============================>


    //<==========ã€è¨“ç·´ç›¸é—œç‰©ä»¶ã€‘=================
    //===ã€å…±ç”¨è®Šæ•¸ã€‘========
    //å‘¨é‚Šç‰©ä»¶
    private FaceDataRecorder dataRecorder;
    //è¨“ç·´è³‡è¨Šè®Šæ•¸(Intentæ¥æ”¶)ï¼‰
    private String trainingLabel = "è¨“ç·´";
    private int trainingType = -1;
    public String trainingLabel_String;
    private FaceLandmarker faceLandmarker;
    //====================================>

    //<========ã€èˆŒé ­ã€‘ ========
    //æ¨è«–é »ç‡æ§åˆ¶ï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰
    private static final int FACE_MESH_EVERY = 5;   // æ¯ 5 å¹€æ›´æ–°ä¸€æ¬¡ã€Œå˜´å·´ ROIã€
    private static final int YOLO_EVERY   = 2;  // æ¯ 3 å¹€è·‘ä¸€æ¬¡ YOLO
    private long firstMetricTime = 0;

    // å‘¨é‚Šç‰©ä»¶
    private TongueYoloDetector tongueDetector;
    private TongueYoloDetectorLR tongueDetectorLR;
    private boolean isYoloEnabled = false;
    // ROIå¿«å–çµ¦YOLOï¼ˆOverlay/Bitmap å…©å¥—åº§æ¨™ç³»ï¼‰
    private Rect lastOverlayRoi = null;
    private Rect lastBitmapRoi  = null;
    //====================================>

    //<========ã€è‡‰é °ã€‘==========
    // å‘¨é‚Šç‰©ä»¶
    private CheekFlowEngine cheekEngine;
    //================================>

    //<=========ã€UXé¡¯ç¤ºå€å¡Šç›¸é—œã€‘==========================
    //è‡‰éƒ¨åœ“æ¡†
    private CircleOverlayView overlayView;
    //æ–‡å­—é¡¯ç¤º
    private TextView statusText;
    private TextView cueText; // æ–°å¢ï¼šå°å¼•å°ˆç”¨ TextView
    private TextView timerText;
    //é€²åº¦æ¢
    private ProgressBar progressBar;

    //åœ“æ¡†ç‹€æ…‹ç®¡ç†
    private enum AppState { DEMO,CALIBRATING, MAINTAINING, OUT_OF_BOUNDS }
    private AppState currentState = AppState.CALIBRATING;
    private boolean isDemoPhase = false;

    //æ–°å¢ç±ƒæ¡†
    // --- æ ¡æ­£ç¤ºç¯„ï¼ˆè—è‰²ï¼‰ç”¨çš„æ——æ¨™ï¼Œåªåœ¨ CALIBRATING å…§ç”Ÿæ•ˆ ---
    private boolean demoEnabled  = true;   // è¦ä¸è¦è·‘ç¤ºç¯„ï¼ˆå¯ç•™ trueï¼‰
    private boolean demoStarted  = false;  // æ˜¯å¦å·²å•Ÿå‹•ä¸€æ¬¡
    private boolean demoFinished = false;  // æ˜¯å¦å·²å®Œæ•´è·‘å®Œä¸€æ¬¡
    private long demoStartMs     = 0L;     // èµ·å§‹æ™‚é–“ï¼ˆmsï¼‰

    //===========ã€UXé¡¯ç¤ºå€å¡Šç›¸é—œã€‘===============>

    //<==============è¨ˆæ™‚è¨­è¨ˆå¸¸æ•¸==============
    private static final int CALIBRATION_TIME = 11000;         // æ ¡æ­£æ™‚é–“(æ¯«ç§’)
    private static final int MAINTAIN_TIME_TOTAL = 20000;     // ç¶­æŒæ™‚é–“(æ¯«ç§’)
    private static final int PROGRESS_UPDATE_INTERVAL = 50;   // é€²åº¦æ¢æ›´æ–°é–“éš”
    // è¨ˆæ™‚è®Šæ•¸
    private long calibrationStartTime = 0;
    private long maintainStartTime = 0;
    private long maintainTotalTime = 0;
    private boolean isTrainingCompleted = false;
    // é–‹å§‹çµæŸæ™‚é–“
    private long TraingStartTime;
    private long TraingEndTime;
    // ç´€éŒ„ç•¶å‰å¹€æ•¸
    private int frameId = 0;
    //==============è¨ˆæ™‚è¨­è¨ˆå¸¸æ•¸==============>

    // =======ã€å‹•ä½œå°å¼•æ–‡å­—æç¤ºã€‘==========================
    private static final boolean SHOW_GUIDE = false; // â† å…¨åŸŸï¼šè¦ä¸è¦æ•™å­¸
    // å°å¼•ç–Šå­—èˆ‡å¾ªç’°æ§åˆ¶ï¼ˆä¸å½±éŸ¿ä½ åŸæœ¬ Handler/Timerï¼‰
    private android.os.Handler cueHandler;
    private java.lang.Runnable cueRunnable;
    private boolean cueRunning = false;
    private int cueStep = 0; // å¾ªç’°ï¼Œæ ¹æ“šé¤˜æ•¸é¡¯ç¤º
    public int CUE_SEGMENT_SEC = 4; // å¯èª¿ï¼šå°å¼•æ–‡å­—é–“éš”ç§’æ•¸ï¼ˆé è¨­ 3 ç§’ï¼‰
    private android.widget.TextView cueTextView; // ç•«é¢ä¸Šçš„å°å¼•æç¤ºæ–‡å­—
    private String currentCueLabel = "è¨“ç·´";      // æœƒç”¨ trainingLabel è½‰æˆç›¸å°æŒ‡å¼•å…§æ–‡
    //===============================================




    //================

    //===========01ã€ç”Ÿå‘½é€±æœŸã€‘========================
    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_face_circle_checker);

        // OpenCV åˆå§‹åŒ–
        if (!OpenCVLoader.initDebug()) {
            Log.e(TAG, "âŒ OpenCVLoader.initDebug() å¤±æ•—");
        } else {
            Log.d(TAG, "âœ… OpenCV åˆå§‹åŒ–æˆåŠŸ");
        }

        // è®€å–å‰ä¸€é é¸æ“‡çš„é‹å‹•é¡å‹
        trainingType  = getIntent().getIntExtra("training_type", -1);
        trainingLabel = getIntent().getStringExtra("training_type");
        // æ›¿trainingLabelå‚™ä»½ï¼Œä¸å¯ç·¨è¼¯
        trainingLabel_String = getIntent().getStringExtra("training_type");

        if (trainingLabel == null) trainingLabel = "è¨“ç·´";
        Log.d(TAG, "æ¥æ”¶åˆ°è¨“ç·´é¡å‹: " + trainingType + ", æ¨™ç±¤: " + trainingLabel);
        // èˆŒé ­æ¨¡å¼æ™‚ : é¡å¤–åˆå§‹åŒ–Yoloåµæ¸¬å™¨
        if ("èˆŒé ­".equals(trainingLabel) ||
                "TONGUE_LEFT".equals(trainingLabel) ||
                "TONGUE_RIGHT".equals(trainingLabel) ||
                "TONGUE_FOWARD".equals(trainingLabel) ||
                "TONGUE_BACK".equals(trainingLabel) ||
                "TONGUE_UP".equals(trainingLabel) ||
                "TONGUE_DOWN".equals(trainingLabel)) {
            initializeTongueDetector();
            Log.d("Confirm what trainingLabel is: ", trainingLabel);
            Log.d(TAG, "âœ… èˆŒé ­æ¨¡å¼ï¼šä½¿ç”¨ MediaPipe é—œéµé»é¡¯ç¤ºèˆ‡å•Ÿç”¨ YOLO æª¢æ¸¬ + YOLO é¡¯ç¤º");
        } else {
            Log.d(TAG, "âœ… éèˆŒé ­æ¨¡å¼ï¼šä½¿ç”¨ MediaPipe é—œéµé»é¡¯ç¤º");
        }

        // åˆå§‹åŒ–è³‡æ–™è¨˜éŒ„å™¨
        dataRecorder = new FaceDataRecorder(this, trainingLabel, trainingType);
        Log.d(TAG, "è³‡æ–™è¨˜éŒ„å™¨åˆå§‹åŒ–å®Œæˆ");

        // ç¶å®šUIæ§ä»¶
        cameraView  = findViewById(R.id.camera_view);
        overlayView = findViewById(R.id.overlay_view);
        statusText  = findViewById(R.id.status_text);
        timerText   = findViewById(R.id.timer_text);
        progressBar = findViewById(R.id.progress_bar);
        cueText     = findViewById(R.id.cue_text);

        // åˆå§‹åŒ–è¿½è¹¤ç¤ºæ„æ¨¡å¼ : èˆŒé ­é¡¯ç¤ºBBoxï¼Œå…¶ä»–é¡¯ç¤ºLandmark
        if ("èˆŒé ­".equals(trainingLabel) ||
                "TONGUE_LEFT".equals(trainingLabel) ||
                "TONGUE_RIGHT".equals(trainingLabel) ||
                "TONGUE_FOWARD".equals(trainingLabel) ||
                "TONGUE_BACK".equals(trainingLabel) ||
                "TONGUE_UP".equals(trainingLabel) ||
                "TONGUE_DOWN".equals(trainingLabel)) {
            overlayView.setDisplayMode(CircleOverlayView.DisplayMode.YOLO_DETECTION);
        } else {
            overlayView.setDisplayMode(CircleOverlayView.DisplayMode.LANDMARKS);
        }

        // åŸ·è¡Œç·’èˆ‡ Handler
        cameraExecutor = Executors.newSingleThreadExecutor();
        yoloExecutor   = Executors.newSingleThreadExecutor();
        mainHandler    = new Handler(Looper.getMainLooper());

        // /åµæ¸¬/UIåˆå§‹åŒ–
        testCameraPermission();
        setupFaceLandmarker();
        initializeUI();

        // ç›¸æ©Ÿæ¬Šé™è™•ç†ï¼šæœ‰å°±æ‰“é–‹ï¼Œæ²’æœ‰å°±è«‹æ±‚ã€‚
        if (checkCameraPermission()) {
            startCamera();
        } else {
            requestCameraPermission();
        }
        // é€²ä¾†å°±é¡¯ç¤ºæ•™å­¸ï¼ˆBottomSheetï¼‰ è¨»è§£æ‰ï¼Œèªªæ˜ä¸åœ¨æ­¤_20250905
        //new Handler(Looper.getMainLooper()).post(this::maybeShowGuideAndStart);
    }

    @Override
    protected void onDestroy() {
        // ğŸ¥ å¦‚æœé‚„åœ¨éŒ„å½±ä¸”è¨“ç·´æœªå®Œæˆï¼Œåˆªé™¤å½±ç‰‡
        if (currentRecording != null) {
            currentRecording.stop();
            currentRecording = null;

            // åˆªé™¤æœªå®Œæˆçš„å½±ç‰‡
            if (videoFilePath != null && !isTrainingCompleted) {
                new Handler(Looper.getMainLooper()).postDelayed(() -> {
                    File file = new File(videoFilePath);
                    if (file.exists() && file.delete()) {
                        Log.d(TAG, "ğŸ—‘ï¸ å·²åˆªé™¤æœªå®Œæˆçš„å½±ç‰‡");
                    }
                }, 500);
            }
        }

        stopSimpleCue();
        super.onDestroy();
        // 1) åœå…¥å£ï¼šä¹‹å¾Œä¸è¦å†æäº¤ä»»ä½•æ–°ä»»å‹™
        isStopping = true;

        // 2) å…ˆæŠŠ UI/Timer callback åœæ‰ï¼Œé¿å…åˆæ’æ–°ä»»å‹™
        cancelTimers();
        if (progressUpdater != null) {
            mainHandler.removeCallbacks(progressUpdater);
            progressUpdater = null;
        }

        // 3) å…ˆåœç›¸æ©Ÿè³‡æ–™æºï¼Œé¿å…é‚„æœ‰æ–°å½±æ ¼æ¹§å…¥ï¼ˆå¾ˆé—œéµï¼‰
        try {
            if (cameraProvider != null) {
                cameraProvider.unbindAll();
            }
        } catch (Exception ignore) { }

        // 4) åœæ‰èƒŒæ™¯åŸ·è¡Œç·’ä¸¦ã€Œç­‰å®ƒåœä¹¾æ·¨ã€
        awaitShutdown(cameraExecutor);
        awaitShutdown(yoloExecutor);

        // 5) åŸ·è¡Œç·’éƒ½åœäº†ï¼Œç¾åœ¨æ‰å®‰å…¨é‡‹æ”¾å„å¼•æ“/åµæ¸¬å™¨
        if (cheekEngine != null) {
            try {
                cheekEngine.release();
            } catch (Throwable ignore) { }
            cheekEngine = null;
        }

        if (tongueDetector != null) {
            try {
                tongueDetector.release();
            } catch (Throwable ignore) { }
            tongueDetector = null;
            Log.d(TAG, "âœ… YOLO æª¢æ¸¬å™¨è³‡æºå·²æ¸…ç†");
        }

        if (tongueDetectorLR != null) {
            try {
                tongueDetectorLR.release();
            } catch (Throwable ignore) { }
            tongueDetectorLR = null;
            Log.d(TAG, "âœ… YOLO æª¢æ¸¬å™¨è³‡æºå·²æ¸…ç†");
        }

        if (faceLandmarker != null) {
            try {
                faceLandmarker.close();
            } catch (Throwable ignore) { }
            faceLandmarker = null;
        }

        // 6) åƒè¬ä¸è¦åœ¨ onDestroy æ¸… CSVï¼Œå¦å‰‡çµæœé æœƒæ‹¿åˆ°ç©ºè³‡æ–™
        // if (dataRecorder != null) { dataRecorder.clearData(); }  // â† ç§»é™¤é€™è¡Œ
    }
    //===========01ã€ç”Ÿå‘½é€±æœŸã€‘========================



    // åˆå§‹åŒ– FaceLandmarker
    private void setupFaceLandmarker() {
        try {
            Log.d(TAG, "try to FaceLandmarker åˆå§‹åŒ–");
            FaceLandmarker.FaceLandmarkerOptions options = FaceLandmarker.FaceLandmarkerOptions.builder()
                    .setBaseOptions(BaseOptions.builder()
                            .setModelAssetPath("face_landmarker.task")
                            .build())
                    .setRunningMode(RunningMode.IMAGE)
                    .setNumFaces(1)
                    .build();
            faceLandmarker = FaceLandmarker.createFromOptions(this, options);
            Log.d(TAG, "FaceLandmarker åˆå§‹åŒ–æˆåŠŸ");
        } catch (Exception e) {
            Log.e(TAG, "FaceLandmarker åˆå§‹åŒ–éŒ¯èª¤: " + e.getMessage());
        }
    }
    // åˆå§‹åŒ–èˆŒé ­æª¢æ¸¬å™¨
    private void initializeTongueDetector() {
        try {
            tongueDetector = new TongueYoloDetector(this);

            isYoloEnabled = tongueDetector.isInitialized();
            if (!isYoloEnabled) {
                Log.e(TAG, "âŒ èˆŒé ­æª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—");
                Toast.makeText(this, "èˆŒé ­æª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡ä½¿ç”¨ä¸€èˆ¬æ¨¡å¼", Toast.LENGTH_SHORT).show();
            }
        } catch (Exception e) {
            Log.e(TAG, "âŒ èˆŒé ­æª¢æ¸¬å™¨åˆå§‹åŒ–éŒ¯èª¤: " + e.getMessage());
            isYoloEnabled = false;
            Toast.makeText(this, "èˆŒé ­æª¢æ¸¬å™¨è¼‰å…¥å¤±æ•—ï¼š" + e.getMessage(), Toast.LENGTH_LONG).show();
        }

        try {
            tongueDetectorLR = new TongueYoloDetectorLR(this);

            isYoloEnabled = tongueDetectorLR.isInitialized();
            if (!isYoloEnabled) {
                Log.e(TAG, "âŒ LRèˆŒé ­æª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—");
                Toast.makeText(this, "LRèˆŒé ­æª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡ä½¿ç”¨ä¸€èˆ¬æ¨¡å¼", Toast.LENGTH_SHORT).show();
            }
        } catch (Exception e) {
            Log.e(TAG, "âŒ LRèˆŒé ­æª¢æ¸¬å™¨åˆå§‹åŒ–éŒ¯èª¤: " + e.getMessage());
            isYoloEnabled = false;
            Toast.makeText(this, "LRèˆŒé ­æª¢æ¸¬å™¨è¼‰å…¥å¤±æ•—ï¼š" + e.getMessage(), Toast.LENGTH_LONG).show();
        }
    }

    private void initializeUI() {
        progressBar.setMax(100);
        progressBar.setProgress(0);
        updateStatusDisplay();
        updateTimerDisplay();
        startProgressUpdater();
    }
    //  è‡ªæˆ‘æª¢æŸ¥ç›¸æ©Ÿæ¬Šé™
    private void testCameraPermission() {
        Log.d(TAG, "é–‹å§‹æª¢æŸ¥ç›¸æ©Ÿæ¬Šé™");
        int cameraPermission = ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA);
        Log.d(TAG, "ç›¸æ©Ÿæ¬Šé™ç‹€æ…‹: " + cameraPermission);
        Log.d(TAG, "PERMISSION_GRANTED å¸¸æ•¸: " + PackageManager.PERMISSION_GRANTED);
        Log.d(TAG, "PERMISSION_DENIED å¸¸æ•¸: " + PackageManager.PERMISSION_DENIED);

        PackageManager pm = getPackageManager();
        boolean hasCamera = pm.hasSystemFeature(PackageManager.FEATURE_CAMERA);
        boolean hasFrontCamera = pm.hasSystemFeature(PackageManager.FEATURE_CAMERA_FRONT);

        Log.d(TAG, "ç³»çµ±æ”¯æ´ç›¸æ©Ÿ: " + hasCamera);
        Log.d(TAG, "ç³»çµ±æ”¯æ´å‰ç½®ç›¸æ©Ÿ: " + hasFrontCamera);
    }

    private boolean checkCameraPermission() {
        return ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA)
                == PackageManager.PERMISSION_GRANTED;
    }
    //è«‹æ±‚Userçµ¦ç›¸æ©Ÿæ¬Šé™
    private void requestCameraPermission() {
        ActivityCompat.requestPermissions(this, new String[]{Manifest.permission.CAMERA}, PERMISSION_REQUEST_CODE);
        Log.d("FaceCircleCheckerActivity","in to requestCameraPermission");
    }


    //å°ˆæ¡ˆå…§æ²’æœ‰ç”¨åˆ°
    @Override
    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
        if (requestCode == PERMISSION_REQUEST_CODE) {
            if (grantResults.length > 0 && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                startCamera();
            } else {
                Toast.makeText(this, "éœ€è¦ç›¸æ©Ÿæ¬Šé™æ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½", Toast.LENGTH_LONG).show();
                finish();
            }
        }
    }
    //ç›´æ¥é–‹å•Ÿç›¸æ©Ÿ(éœ€è¦å…ˆè«‹æ±‚å¥½æ¬Šé™)
    private void startCamera() {
        ListenableFuture<ProcessCameraProvider> cameraProviderFuture = ProcessCameraProvider.getInstance(this);
        cameraProviderFuture.addListener(() -> {
            try {
                cameraProvider = cameraProviderFuture.get();
                bindCameraUseCases();
            } catch (ExecutionException | InterruptedException e) {
                Log.e(TAG, "ç›¸æ©Ÿåˆå§‹åŒ–å¤±æ•—", e);
                Toast.makeText(this, "ç›¸æ©Ÿåˆå§‹åŒ–å¤±æ•—", Toast.LENGTH_SHORT).show();
            }
        }, ContextCompat.getMainExecutor(this));
    }

    private void bindCameraUseCases() {
        Preview preview = new Preview.Builder().build();
        preview.setSurfaceProvider(cameraView.getSurfaceProvider());

        ImageAnalysis imageAnalysis = new ImageAnalysis.Builder()
                .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                .build();

        imageAnalysis.setAnalyzer(cameraExecutor, this::analyzeImage);

        CameraSelector cameraSelector = CameraSelector.DEFAULT_FRONT_CAMERA;

        // ğŸ¥ å‰µå»º VideoCapture
        if (ENABLE_VIDEO_RECORDING) {
            try {
                Recorder recorder = new Recorder.Builder()
                        .setQualitySelector(QualitySelector.from(Quality.HD))
                        .build();
                videoCapture = VideoCapture.withOutput(recorder);
                Log.d(TAG, "âœ… VideoCapture åˆå§‹åŒ–æˆåŠŸ");
            } catch (Exception e) {
                Log.e(TAG, "âŒ VideoCapture åˆå§‹åŒ–å¤±æ•—", e);
            }
        }

        try {
            cameraProvider.unbindAll();

            // ğŸ¥ ç¶å®šç›¸æ©Ÿç”¨ä¾‹ï¼ˆåŒ…å«éŒ„å½±ï¼‰
            if (ENABLE_VIDEO_RECORDING && videoCapture != null) {
                cameraProvider.bindToLifecycle(this, cameraSelector, preview, imageAnalysis, videoCapture);
            } else {
                cameraProvider.bindToLifecycle(this, cameraSelector, preview, imageAnalysis);
            }

            Log.d(TAG, "ç›¸æ©Ÿç¶å®šæˆåŠŸ");
        } catch (Exception e) {
            Log.e(TAG, "ç›¸æ©Ÿç¶å®šå¤±æ•—", e);
            Toast.makeText(this, "ç›¸æ©Ÿå•Ÿå‹•å¤±æ•—", Toast.LENGTH_SHORT).show();
        }
    }

    // åœ–åƒåˆ†æ
    private void analyzeImage(@NonNull ImageProxy imageProxy) {
        if (faceLandmarker == null) {
            imageProxy.close();
            return;
        }

        try {
            int rotationDegrees = imageProxy.getImageInfo().getRotationDegrees();
            Bitmap rawBitmap = imageProxyToBitmap(imageProxy);
            if (rawBitmap != null) {
                Bitmap rotatedBitmap = rotateBitmap(rawBitmap, rotationDegrees);
                Bitmap mirroredBitmap = mirrorBitmap(rotatedBitmap);

                MPImage mpImage = new BitmapImageBuilder(mirroredBitmap).build();
                FaceLandmarkerResult result = faceLandmarker.detect(mpImage);

                if (result != null && !result.faceLandmarks().isEmpty()) {
                    Log.d(TAG, "æª¢æ¸¬åˆ°äººè‡‰ï¼Œé—œéµé»æ•¸é‡: " + result.faceLandmarks().get(0).size());
                }
                //checkFacePositioné€²å…¥å¾Œæœƒæ ¹æ“šå‹•ä½œåˆ†æµ
                checkFacePosition(result, mirroredBitmap.getWidth(), mirroredBitmap.getHeight(), mirroredBitmap);

                new Handler(Looper.getMainLooper()).postDelayed(() -> {
                    rawBitmap.recycle();
                    if (rotatedBitmap != rawBitmap) rotatedBitmap.recycle();
                    // mirroredBitmap äº¤ç”± GC
                }, 100);
            }
        } catch (Exception e) {
            Log.e(TAG, "åœ–åƒåˆ†æéŒ¯èª¤", e);
        } finally {
            // â­ æ¯å¹€çµæŸè‡ªå¢ï¼ˆçµ±ä¸€å¹€ç¯€å¥ï¼‰
            frameId++;
            imageProxy.close();
        }
    }

    private Bitmap rotateBitmap(Bitmap original, int degrees) {
        if (degrees == 0) return original;
        Matrix matrix = new Matrix();
        matrix.postRotate(degrees);
        return Bitmap.createBitmap(original, 0, 0, original.getWidth(), original.getHeight(), matrix, true);
    }

    private Bitmap mirrorBitmap(Bitmap original) {
        Matrix matrix = new Matrix();
        matrix.preScale(-1.0f, 1.0f);
        return Bitmap.createBitmap(original, 0, 0, original.getWidth(), original.getHeight(), matrix, false);
    }

    private Bitmap imageProxyToBitmap(@NonNull ImageProxy imageProxy) {
        try {
            ImageProxy.PlaneProxy[] planes = imageProxy.getPlanes();
            ByteBuffer yBuffer = planes[0].getBuffer();
            ByteBuffer uBuffer = planes[1].getBuffer();
            ByteBuffer vBuffer = planes[2].getBuffer();

            int ySize = yBuffer.remaining();
            int uSize = uBuffer.remaining();
            int vSize = vBuffer.remaining();

            byte[] nv21 = new byte[ySize + uSize + vSize];
            yBuffer.get(nv21, 0, ySize);

            byte[] uvPixelBuffer = new byte[uSize + vSize];
            vBuffer.get(uvPixelBuffer, 0, vSize);
            uBuffer.get(uvPixelBuffer, vSize, uSize);

            int uvPixelCount = 0;
            for (int i = ySize; i < nv21.length; i += 2) {
                nv21[i] = uvPixelBuffer[uvPixelCount];
                nv21[i + 1] = uvPixelBuffer[uvPixelCount + 1];
                uvPixelCount += 2;
            }

            YuvImage yuvImage = new YuvImage(nv21, ImageFormat.NV21,
                    imageProxy.getWidth(), imageProxy.getHeight(), null);
            ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
            yuvImage.compressToJpeg(new Rect(0, 0,
                    imageProxy.getWidth(), imageProxy.getHeight()), 100, outputStream);
            byte[] imageBytes = outputStream.toByteArray();

            return BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.length);

        } catch (Exception e) {
            Log.e(TAG, "ImageProxyè½‰æ›éŒ¯èª¤", e);
            return null;
        }
    }


    /**
     * å°‡ allPoints è½‰æˆã€ŒBitmap åƒç´ åº§æ¨™ã€ã€‚
     * - è‹¥çœ‹èµ·ä¾†æ˜¯ normalized(0~1) â†’ ä¹˜ä¸Š imgW/imgHã€‚
     * - å¦å‰‡è¦–ç‚º Overlay åº§æ¨™ â†’ ä¾ç­‰æ¯”ç¸®æ”¾+ç½®ä¸­æ¨¡å‹åæ¨å› Bitmap åƒç´ ã€‚
     */
    private float[][] toBitmapPixels(float[][] ptsIn,
                                     int imgW, int imgH,
                                     int overlayW, int overlayH) {
        float[][] out = new float[ptsIn.length][2];

        // ç²—æª¢ï¼šæŠ½æ¨£å‰20é»ï¼Œæœ‰ â‰¥70% è½åœ¨[0,1] å°±ç•¶ normalized
        int sample = Math.min(20, ptsIn.length), count01 = 0;
        for (int i = 0; i < sample; i++) {
            float x = ptsIn[i][0], y = ptsIn[i][1];
            if (x >= 0f && x <= 1f && y >= 0f && y <= 1f) count01++;
        }
        boolean looksNormalized = (count01 >= sample * 0.7f);

        if (looksNormalized) {
            for (int i = 0; i < ptsIn.length; i++) {
                out[i][0] = ptsIn[i][0] * imgW;
                out[i][1] = ptsIn[i][1] * imgH;
            }
            return out;
        }

        // Overlayâ†’Bitmap åè§£ï¼ˆview = img*scale + offsetï¼‰
        float scale = Math.min((float) overlayW / imgW, (float) overlayH / imgH);
        float offX = (overlayW - imgW * scale) / 2f;
        float offY = (overlayH - imgH * scale) / 2f;

        for (int i = 0; i < ptsIn.length; i++) {
            float vx = ptsIn[i][0], vy = ptsIn[i][1];
            out[i][0] = (vx - offX) / scale;
            out[i][1] = (vy - offY) / scale;
        }
        return out;
    }

    //===========ã€å‹•ä½œæ–¹æ³•å€åŸŸã€‘=========
    // åŠ å…¥ YOLO æ•´åˆ
    private void checkFacePosition(FaceLandmarkerResult result, int bitmapWidth, int bitmapHeight, Bitmap mirroredBitmap) {
        boolean faceDetected = result != null && !result.faceLandmarks().isEmpty();

        if (faceDetected) {
            try {
                runOnUiThread(() -> {
//                    Log.d(TAG_2, "é€²å…¥ä¸»æµç¨‹_checkFacePosition");
                    int overlayWidth = overlayView.getWidth();
                    int overlayHeight = overlayView.getHeight();
                    //  å‰ç½®é¡é ­é¡¯ç¤ºå½±åƒä¸æ˜¯çœŸçš„ï¼Œæ˜¯è™•ç†éçš„ï¼ŒMEDIAPPIPEè™•ç†çš„é™£åˆ—æ˜¯æœªè™•ç†å¾—"ç›¸æ©Ÿé™£åˆ—"ï¼Œæ‰€ä»¥é€™é‚Šé€²è¡Œæ¨¡ä»¿è™•ç†å†é¡¯ç¤º
                    if (overlayWidth > 0 && overlayHeight > 0) {
                        float inputAspect = 480f / 640f; // Bitmap å¯¬é«˜æ¯”(?bitmapå¾å“ªä¾†ï¼Œå‰ç½®é¡é ­åŸå§‹åƒ?)
                        float viewAspect = overlayWidth / (float) overlayHeight; // Overlay å¯¬é«˜æ¯”(çµ¦äººçœ‹å¾—è™•ç†å¾Œç•«é¢?)
                        float scaleX = inputAspect / viewAspect;

                        int landmarkCount = result.faceLandmarks().get(0).size();
                        float[][] landmarks01 = new float[landmarkCount][3]; // 0~1;//æ­£è¦åŒ–åŸå§‹åœ–åƒ
                        float[][] allPoints = new float[landmarkCount][3]; // 0~1;//è®Šå½¢æ¯”ä¾‹ï¼Œé¡¯ç¤ºç”¨åœ–åƒ

                        for (int i = 0; i < landmarkCount; i++) {
                            float x = result.faceLandmarks().get(0).get(i).x();
                            float y = result.faceLandmarks().get(0).get(i).y();
                            float z = result.faceLandmarks().get(0).get(i).z();

                            // å­˜ä¸€ä»½åŸå§‹ 0~1ï¼ˆçµ¦ CheekFlowEngine ç”¨ï¼‰
                            landmarks01[i][0] = x;
                            landmarks01[i][1] = y;
                            landmarks01[i][2] = z;
                            // é€™ä»½æ˜¯çµ¦ overlay ç•«é¢ï¼šåš X æ¯”ä¾‹è£œå„Ÿå¾Œè½‰åƒç´ 
                            x = (x - 0.5f) * scaleX + 0.5f; //???
                            allPoints[i][0] = x * overlayWidth;
                            allPoints[i][1] = y * overlayHeight;
                            allPoints[i][2] = z ;
//                            Log.d(TAG_2, "é€²å…¥ä¸»æµç¨‹_checkFacePosition_å¯«å®Œå…©å€‹allPoints");
                        }
                        //****å‹•ä½œåˆ†æµçµ¦Handleræ–¹æ³•ï¼Œåº•ä¸‹handleFacePositionè™•ç†æ™‚é–“é¡¯ç¤ºæµ
                        if (("TONGUE_FOWARD".equals(trainingLabel) ||
                                "TONGUE_BACK".equals(trainingLabel) ||
                                "TONGUE_UP".equals(trainingLabel) ||
                                "TONGUE_DOWN".equals(trainingLabel)) && isYoloEnabled) {

//                            Log.d(TAG_2, "å‹•ä½œåˆ†æµ_èˆŒé ­");

                            // å¹€æ¨¹éæ¿¾å™¨: æ¯ FACE_MESH_EVERY å¹€æ›´æ–°ä¸€æ¬¡ ROIï¼ˆOverlayâ†’Bitmapï¼‰ï¼ŒneedFaceMesh=éœ€ä¸éœ€è¦æ›´æ–°
                            // æ›´æ›æ©Ÿå‹å¯ä»¥èª¿æ•´çœ‹çœ‹
                            boolean needFaceMesh = (lastOverlayRoi == null) || (frameId % FACE_MESH_EVERY == 0);
                            if (needFaceMesh) {
                                Rect overlayRoi = TongueYoloDetector.calculateMouthROI(allPoints, overlayWidth, overlayHeight);
                                lastOverlayRoi = overlayRoi;
                                //mirroredBitmap =>åœ–å·²è½‰æ­£+å·¦å³é¡›å€’å¾Œ
                                // bé™¤ä»¥sx=oï¼Œæ±‚sxå°±æ˜¯è¦ç®—ç¸®æ”¾å€ç‡
                                float sx = (float) mirroredBitmap.getWidth() / overlayWidth;
                                float sy = (float) mirroredBitmap.getHeight() / overlayHeight;
                                lastBitmapRoi = new Rect(
                                        Math.round(overlayRoi.left * sx),
                                        Math.round(overlayRoi.top * sy),
                                        Math.round(overlayRoi.right * sx),
                                        Math.round(overlayRoi.bottom * sy)
                                );
                            }

                            // æŠŠå¿«å– ROI å‚³çµ¦ YOLOï¼ˆä¸ä¸€å®šæ¯å¹€æ›´æ–° ROIï¼‰
//                            handleTongueMode(allPoints, mirroredBitmap, bitmapWidth, bitmapHeight,
//                                    lastOverlayRoi, lastBitmapRoi);
                            //20025 11 13 å·æ”¹çœ‹çœ‹æ–°æ¨¡å‹
                            handleTongueMode(allPoints, mirroredBitmap, bitmapWidth, bitmapHeight,
                                    lastOverlayRoi, lastBitmapRoi);

                        } else if("TONGUE_LEFT".equals(trainingLabel) || "TONGUE_RIGHT".equals(trainingLabel) ){
//                            Log.d(TAG_2, "å‹•ä½œåˆ†æµ_èˆŒé ­");
                            // å¹€æ¨¹éæ¿¾å™¨: æ¯ FACE_MESH_EVERY å¹€æ›´æ–°ä¸€æ¬¡ ROIï¼ˆOverlayâ†’Bitmapï¼‰ï¼ŒneedFaceMesh=éœ€ä¸éœ€è¦æ›´æ–°
                            // æ›´æ›æ©Ÿå‹å¯ä»¥èª¿æ•´çœ‹çœ‹
                            boolean needFaceMesh = (lastOverlayRoi == null) || (frameId % FACE_MESH_EVERY == 0);
                            if (needFaceMesh) {
                                Rect overlayRoi = TongueYoloDetectorLR.calculateMouthROI(allPoints, overlayWidth, overlayHeight);
                                lastOverlayRoi = overlayRoi;
                                //mirroredBitmap =>åœ–å·²è½‰æ­£+å·¦å³é¡›å€’å¾Œ
                                // bé™¤ä»¥sx=oï¼Œæ±‚sxå°±æ˜¯è¦ç®—ç¸®æ”¾å€ç‡
                                Log.d("confirmLR", "into LR checkPos");
                                float sx = (float) mirroredBitmap.getWidth() / overlayWidth;
                                float sy = (float) mirroredBitmap.getHeight() / overlayHeight;
                                lastBitmapRoi = new Rect(
                                        Math.round(overlayRoi.left * sx),
                                        Math.round(overlayRoi.top * sy),
                                        Math.round(overlayRoi.right * sx),
                                        Math.round(overlayRoi.bottom * sy)
                                );
                            }
                            // æŠŠå¿«å– ROI å‚³çµ¦ YOLOï¼ˆä¸ä¸€å®šæ¯å¹€æ›´æ–° ROIï¼‰
                            handleTongueModeLR(allPoints, mirroredBitmap, bitmapWidth, bitmapHeight,
                                    lastOverlayRoi, lastBitmapRoi);

                        } else if ("é¼“é °".equals(trainingLabel) || "PUFF_CHEEK".equals(trainingLabel) || "REDUCE_CHEEK".equals(trainingLabel)) {
                            //Log.d(TAG_2, "å‹•ä½œåˆ†æµ_è‡‰é °");
                            // â˜…â˜…â˜… è‡‰é °æ¨¡å¼
                            handleCheeksMode(landmarks01, mirroredBitmap,bitmapWidth,bitmapHeight);
                        } else if ("ä¸‹é¡".equals(trainingLabel) || "JAW_LEFT".equals(trainingLabel) || "JAW_RIGHT".equals(trainingLabel)) {
                            // â˜…â˜…â˜… ä¸‹é¡æ¨¡å¼
                            //Log.d(TAG_2, "å‹•ä½œåˆ†æµ_ä¸‹é¡");
                            handleJawMode(allPoints);
                        } else {
                            //Log.d(TAG_2, "å‹•ä½œåˆ†æµ_å˜´å”‡");
                            // å˜´å”‡æ¨¡å¼
                            handleLipMode(allPoints);
                        }
                        // *************************å‰ç«¯é‚è¼¯
                        // é¼»å°– for åœ“æ¡†ç‹€æ…‹ï¼ˆé¡¯ç¤ºå±¤ç”¨ï¼‰
                        float noseRelativeX = result.faceLandmarks().get(0).get(1).x();
                        float noseRelativeY = result.faceLandmarks().get(0).get(1).y();
                        float noseCorrectedX = (noseRelativeX - 0.5f) * scaleX + 0.5f;

                        float noseScreenX = noseCorrectedX * overlayWidth;
                        float noseScreenY = noseRelativeY * overlayHeight;

                        float centerX = overlayWidth / 2f;
                        float centerY = overlayHeight / 2f;
                        float radius = Math.min(centerX, centerY) - 80;

                        float dx = noseScreenX - centerX;
                        float dy = noseScreenY - centerY;
                        boolean noseInside = (dx * dx + dy * dy) <= (radius * radius);

                        handleFacePosition(noseInside);
                    }
                });

            } catch (Exception e) {
                Log.e(TAG, "æª¢æŸ¥è‡‰éƒ¨ä½ç½®æ™‚ç™¼ç”ŸéŒ¯èª¤", e);
                runOnUiThread(() -> handleFacePosition(false));
            }
        } else {
            runOnUiThread(() -> {
                overlayView.clearAllLandmarks();
                overlayView.clearYoloResults();
                handleFacePosition(false);
                Log.d(TAG, "æœªæª¢æ¸¬åˆ°äººè‡‰");
            });
        }
    }

    /**
     * èˆŒé ­æ¨¡å¼ï¼šç”¨å¿«å–å¥½çš„ ROI + ç¯€æµ YOLO
     * æ¨¡å¼è™•ç†åªè² è²¬åˆ°ç´€éŒ„ï¼Œç¨å¾Œç”±ç‹€æ…‹å¹¾å‘¼å«å®Œæˆé€²è¡Œå¾ŒçºŒé‚è¼¯
     * æ”¹TongueYoloDetector.DetectionResult result çš„ç‰©ä»¶1æˆ–2
     */
    private void handleTongueMode(float[][] allPoints, Bitmap mirroredBitmap, int bitmapWidth, int bitmapHeight,
                                  Rect overlayRoi,   // â† ä½¿ç”¨å¿«å– Overlay ROI
                                  Rect bitmapRoi) {  // â† ä½¿ç”¨å¿«å– Bitmap ROI
        try {
            if (!shouldAcceptNewFrames()) return;
            // â˜… æ¯ YOLO_EVERY å¹€è·‘ä¸€æ¬¡ YOLO
            if ((frameId % YOLO_EVERY) != 0) return;
            if (overlayRoi == null || bitmapRoi == null) return;

            int overlayWidth = overlayView.getWidth();
            int overlayHeight = overlayView.getHeight();

            final Rect mouthROIFinal = new Rect(overlayRoi);
            final float[][] allPointsFinal = allPoints;
            final Rect bitmapROIFinal = new Rect(bitmapRoi);

            yoloExecutor.execute(() -> {
                long t0 = System.nanoTime();
                TongueYoloDetector.DetectionResult result =
                        tongueDetector.detectTongueWithRealPosition(
                                mirroredBitmap, bitmapROIFinal, overlayWidth, overlayHeight);
                long t1 = System.nanoTime();
                float inferMs = (t1 - t0) / 1_000_000f;

                Rect viewTongueBox = null;
                if (result.detected && result.boundingBox != null) {
                    float sx = overlayWidth  / (float) mirroredBitmap.getWidth();
                    float sy = overlayHeight / (float) mirroredBitmap.getHeight();
                    Rect b = result.boundingBox;
                    viewTongueBox = new Rect(
                            Math.round(b.left   * sx),
                            Math.round(b.top    * sy),
                            Math.round(b.right  * sx),
                            Math.round(b.bottom * sy)
                    );
                }

                // æ¯ 10 ç§’æ‰“ä¸€è¡Œ METRICS
                // å¥½åƒè·Ÿé›»æ± æœ‰é—œ
                String thermalStr = "N/A";
                try {
                    android.os.PowerManager pm = (android.os.PowerManager) getSystemService(POWER_SERVICE);
                    if (pm != null) {
                        int ts = pm.getCurrentThermalStatus();
                        switch (ts) {
                            case android.os.PowerManager.THERMAL_STATUS_NONE:      thermalStr = "NONE"; break;
                            case android.os.PowerManager.THERMAL_STATUS_LIGHT:     thermalStr = "LIGHT"; break;
                            case android.os.PowerManager.THERMAL_STATUS_MODERATE:  thermalStr = "MODERATE"; break;
                            case android.os.PowerManager.THERMAL_STATUS_SEVERE:    thermalStr = "SEVERE"; break;
                            case android.os.PowerManager.THERMAL_STATUS_CRITICAL:  thermalStr = "CRITICAL"; break;
                            case android.os.PowerManager.THERMAL_STATUS_EMERGENCY: thermalStr = "EMERGENCY"; break;
                            case android.os.PowerManager.THERMAL_STATUS_SHUTDOWN:  thermalStr = "SHUTDOWN"; break;
                            default: thermalStr = String.valueOf(ts);
                        }
                    }
                } catch (Throwable ignore) {}

                long now = System.currentTimeMillis();
                if (firstMetricTime == 0) firstMetricTime = now;
                long elapsed = (now - firstMetricTime) / 1000;
                if (elapsed == 10 || elapsed == 20 || elapsed == 30 || elapsed == 40) {
                    Log.d(TAG, String.format("METRICS@%ds infer=%.1fms bestProb=%.3f thermal=%s",
                            elapsed, inferMs, result.confidence, thermalStr));
                }

                Rect finalViewTongueBox = viewTongueBox;
                //æº–å‚™å¸¶å…¥ä¸»åŸ·è¡Œç·’
                final boolean detected = result.detected;
                final float conf = result.confidence;
                final Rect bboxImgFinal = (result.detected && result.boundingBox != null)
                        ? new Rect(result.boundingBox) : null;
                mainHandler.post(() -> {
                    overlayView.setYoloDetectionResult(detected, conf, finalViewTongueBox, mouthROIFinal);

                    // è¨­å®šåƒè€ƒç·š (ç”¨ View åº§æ¨™)ï¼Œå–®ç´”ç‚ºäº†æŠŠåº§æ¨™ä¸Ÿçµ¦overlayViewç¹ªè£½
                    float eyeRxView = allPointsFinal[33][0], eyeRyView = allPointsFinal[33][1];
                    float eyeLxView = allPointsFinal[263][0], eyeLyView = allPointsFinal[263][1];
                    float browCxView = allPointsFinal[168][0], browCyView = allPointsFinal[168][1];
                    float noseXView = allPointsFinal[1][0], noseYView = allPointsFinal[1][1];
                    overlayView.setReferenceLines(eyeLxView, eyeLyView, eyeRxView, eyeRyView, noseXView, noseYView, browCxView, browCyView);

                    if (!isTrainingCompleted && (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)) {
                        String stateString = csvState();
                        // 1) å½±åƒå°ºå¯¸ï¼ˆBitmap åƒç´ ï¼‰
                        final int imgW = mirroredBitmap.getWidth();
                        final int imgH = mirroredBitmap.getHeight();

                        // 2) YOLO bboxï¼ˆBitmap åƒç´ ï¼›ç„¡åµæ¸¬â†’nullï¼‰
                        final android.graphics.Rect bboxImg = bboxImgFinal;

                        // 3) å°‡ allPointsFinal çµ±ä¸€åˆ°ã€ŒBitmap åƒç´ ã€
                        float[][] ptsPx = toBitmapPixels(allPointsFinal, imgW, imgH, overlayView.getWidth(), overlayView.getHeight());

                        // 4) å–éœ€è¦çš„è‡‰éƒ¨é»ï¼ˆMediaPipe FaceMesh indexï¼‰
                        final int EYE_R = 33, EYE_L = 263, BROW_C = 168, NOSE_T = 1;
                        float eyeRx = ptsPx[EYE_R][0], eyeRy = ptsPx[EYE_R][1];
                        float eyeLx = ptsPx[EYE_L][0], eyeLy = ptsPx[EYE_L][1];
                        float browCx = ptsPx[BROW_C][0],  browCy = ptsPx[BROW_C][1];
                        float noseX  = ptsPx[NOSE_T][0],  noseY  = ptsPx[NOSE_T][1];

                        // 5) è£œæ­£åƒæ•¸ï¼šåŸé»ï¼ˆä½ è¦çš„åŸºæº–é»ï¼‰ï¼Œæ—‹è½‰è§’ï¼ˆå…©çœ¼ç·šï¼‰ã€ç¸®æ”¾ï¼ˆå…©çœ¼è·ï¼‰
                        float originX = noseX, originY = noseY;   // ä½ è¦ç”¨é¼»å°–ç•¶åŸé»
                        float vxEye = eyeRx - eyeLx, vyEye = eyeRy - eyeLy;
                        float dio   = (float) Math.hypot(vxEye, vyEye);       // å…©çœ¼è·
                        float theta = (float) Math.atan2(vyEye, vxEye);       // å…©çœ¼ç·šç›¸å°æ°´å¹³è§’ï¼ˆå¼§åº¦ï¼‰

                        // 6) èˆŒé ­ä¸­å¿ƒï¼ˆBitmap åƒç´ ï¼‰èˆ‡è£œæ­£å¾Œåº§æ¨™
                        float cxImg = Float.NaN, cyImg = Float.NaN, xNorm = Float.NaN, yNorm = Float.NaN;
                        if (bboxImg != null) {
                            cxImg = (bboxImg.left + bboxImg.right) * 0.5f;
                            cyImg = (bboxImg.top  + bboxImg.bottom) * 0.5f;

                            // å¹³ç§»åˆ°åŸé»
                            float vx = cxImg - originX;
                            float vy = cyImg - originY;

                            // æ—‹è½‰ -thetaï¼ˆè®“å…©çœ¼ç·šæ°´å¹³ï¼‰
                            float cosT = (float) Math.cos(theta), sinT = (float) Math.sin(theta);
                            float xr =  vx * cosT + vy * sinT;
                            float yr = -vx * sinT + vy * cosT;

                            // ç¸®æ”¾æ­£è¦åŒ–ï¼ˆé™¤ä»¥å…©çœ¼è·ï¼‰
                            if (dio > 1e-3f) {
                                xNorm = xr / dio;
                                yNorm = yr / dio;
                            }
                        }

                        // 7) å¯«å…¥ï¼šå‘¼å«ã€ŒèˆŒé ­å°ˆç”¨å¤šè¼‰ã€
                        dataRecorder.recordLandmarkData(
                                stateString,
                                detected,
                                bboxImg,
                                eyeLx, eyeLy, eyeRx, eyeRy,
                                browCx, browCy, noseX, noseY,
                                imgW, imgH,
                                System.currentTimeMillis(),
                                originX, originY,
                                theta,
                                dio,
                                cxImg, cyImg,
                                xNorm, yNorm
                        );
                    }
                });
            });

        } catch (Exception e) {
            Log.e(TAG, "è™•ç†èˆŒé ­æ¨¡å¼æ™‚ç™¼ç”ŸéŒ¯èª¤", e);
        }
    }


    private void handleTongueModeLR(float[][] allPoints, Bitmap mirroredBitmap, int bitmapWidth, int bitmapHeight,
                                  Rect overlayRoi,   // â† ä½¿ç”¨å¿«å– Overlay ROI
                                  Rect bitmapRoi) {  // â† ä½¿ç”¨å¿«å– Bitmap ROI
        try {
            if (!shouldAcceptNewFrames()) return;
            // â˜… æ¯ YOLO_EVERY å¹€è·‘ä¸€æ¬¡ YOLO
            if ((frameId % YOLO_EVERY) != 0) return;
            if (overlayRoi == null || bitmapRoi == null) return;

            int overlayWidth = overlayView.getWidth();
            int overlayHeight = overlayView.getHeight();

            final Rect mouthROIFinal = new Rect(overlayRoi);
            final float[][] allPointsFinal = allPoints;
            final Rect bitmapROIFinal = new Rect(bitmapRoi);

            yoloExecutor.execute(() -> {
                long t0 = System.nanoTime();
                TongueYoloDetectorLR.DetectionResult result =
                        tongueDetectorLR.detectTongueWithRealPosition(
                                mirroredBitmap, bitmapROIFinal, overlayWidth, overlayHeight);
                Log.d("confirmLR", "into LR handle");
                long t1 = System.nanoTime();
                float inferMs = (t1 - t0) / 1_000_000f;

                Rect viewTongueBox = null;
                if (result.detected && result.boundingBox != null) {
                    float sx = overlayWidth  / (float) mirroredBitmap.getWidth();
                    float sy = overlayHeight / (float) mirroredBitmap.getHeight();
                    Rect b = result.boundingBox;
                    viewTongueBox = new Rect(
                            Math.round(b.left   * sx),
                            Math.round(b.top    * sy),
                            Math.round(b.right  * sx),
                            Math.round(b.bottom * sy)
                    );
                }

                // æ¯ 10 ç§’æ‰“ä¸€è¡Œ METRICS
                // å¥½åƒè·Ÿé›»æ± æœ‰é—œ
                String thermalStr = "N/A";
                try {
                    android.os.PowerManager pm = (android.os.PowerManager) getSystemService(POWER_SERVICE);
                    if (pm != null) {
                        int ts = pm.getCurrentThermalStatus();
                        switch (ts) {
                            case android.os.PowerManager.THERMAL_STATUS_NONE:      thermalStr = "NONE"; break;
                            case android.os.PowerManager.THERMAL_STATUS_LIGHT:     thermalStr = "LIGHT"; break;
                            case android.os.PowerManager.THERMAL_STATUS_MODERATE:  thermalStr = "MODERATE"; break;
                            case android.os.PowerManager.THERMAL_STATUS_SEVERE:    thermalStr = "SEVERE"; break;
                            case android.os.PowerManager.THERMAL_STATUS_CRITICAL:  thermalStr = "CRITICAL"; break;
                            case android.os.PowerManager.THERMAL_STATUS_EMERGENCY: thermalStr = "EMERGENCY"; break;
                            case android.os.PowerManager.THERMAL_STATUS_SHUTDOWN:  thermalStr = "SHUTDOWN"; break;
                            default: thermalStr = String.valueOf(ts);
                        }
                    }
                } catch (Throwable ignore) {}

                long now = System.currentTimeMillis();
                if (firstMetricTime == 0) firstMetricTime = now;
                long elapsed = (now - firstMetricTime) / 1000;
                if (elapsed == 10 || elapsed == 20 || elapsed == 30 || elapsed == 40) {
                    Log.d(TAG, String.format("METRICS@%ds infer=%.1fms bestProb=%.3f thermal=%s",
                            elapsed, inferMs, result.confidence, thermalStr));
                }

                Rect finalViewTongueBox = viewTongueBox;
                //æº–å‚™å¸¶å…¥ä¸»åŸ·è¡Œç·’
                final boolean detected = result.detected;
                final float conf = result.confidence;
                final Rect bboxImgFinal = (result.detected && result.boundingBox != null)
                        ? new Rect(result.boundingBox) : null;
                mainHandler.post(() -> {
                    overlayView.setYoloDetectionResult(detected, conf, finalViewTongueBox, mouthROIFinal);

                    // è¨­å®šåƒè€ƒç·š (ç”¨ View åº§æ¨™)ï¼Œå–®ç´”ç‚ºäº†æŠŠåº§æ¨™ä¸Ÿçµ¦overlayViewç¹ªè£½
                    float eyeRxView = allPointsFinal[33][0], eyeRyView = allPointsFinal[33][1];
                    float eyeLxView = allPointsFinal[263][0], eyeLyView = allPointsFinal[263][1];
                    float browCxView = allPointsFinal[168][0], browCyView = allPointsFinal[168][1];
                    float noseXView = allPointsFinal[1][0], noseYView = allPointsFinal[1][1];
                    overlayView.setReferenceLines(eyeLxView, eyeLyView, eyeRxView, eyeRyView, noseXView, noseYView, browCxView, browCyView);

                    if (!isTrainingCompleted && (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)) {
                        String stateString = csvState();
                        // 1) å½±åƒå°ºå¯¸ï¼ˆBitmap åƒç´ ï¼‰
                        final int imgW = mirroredBitmap.getWidth();
                        final int imgH = mirroredBitmap.getHeight();

                        // 2) YOLO bboxï¼ˆBitmap åƒç´ ï¼›ç„¡åµæ¸¬â†’nullï¼‰
                        final android.graphics.Rect bboxImg = bboxImgFinal;

                        // 3) å°‡ allPointsFinal çµ±ä¸€åˆ°ã€ŒBitmap åƒç´ ã€
                        float[][] ptsPx = toBitmapPixels(allPointsFinal, imgW, imgH, overlayView.getWidth(), overlayView.getHeight());

                        // 4) å–éœ€è¦çš„è‡‰éƒ¨é»ï¼ˆMediaPipe FaceMesh indexï¼‰
                        final int EYE_R = 33, EYE_L = 263, BROW_C = 168, NOSE_T = 1;
                        float eyeRx = ptsPx[EYE_R][0], eyeRy = ptsPx[EYE_R][1];
                        float eyeLx = ptsPx[EYE_L][0], eyeLy = ptsPx[EYE_L][1];
                        float browCx = ptsPx[BROW_C][0],  browCy = ptsPx[BROW_C][1];
                        float noseX  = ptsPx[NOSE_T][0],  noseY  = ptsPx[NOSE_T][1];

                        // 5) è£œæ­£åƒæ•¸ï¼šåŸé»ï¼ˆä½ è¦çš„åŸºæº–é»ï¼‰ï¼Œæ—‹è½‰è§’ï¼ˆå…©çœ¼ç·šï¼‰ã€ç¸®æ”¾ï¼ˆå…©çœ¼è·ï¼‰
                        float originX = noseX, originY = noseY;   // ä½ è¦ç”¨é¼»å°–ç•¶åŸé»
                        float vxEye = eyeRx - eyeLx, vyEye = eyeRy - eyeLy;
                        float dio   = (float) Math.hypot(vxEye, vyEye);       // å…©çœ¼è·
                        float theta = (float) Math.atan2(vyEye, vxEye);       // å…©çœ¼ç·šç›¸å°æ°´å¹³è§’ï¼ˆå¼§åº¦ï¼‰

                        // 6) èˆŒé ­ä¸­å¿ƒï¼ˆBitmap åƒç´ ï¼‰èˆ‡è£œæ­£å¾Œåº§æ¨™
                        float cxImg = Float.NaN, cyImg = Float.NaN, xNorm = Float.NaN, yNorm = Float.NaN;
                        if (bboxImg != null) {
                            cxImg = (bboxImg.left + bboxImg.right) * 0.5f;
                            cyImg = (bboxImg.top  + bboxImg.bottom) * 0.5f;

                            // å¹³ç§»åˆ°åŸé»
                            float vx = cxImg - originX;
                            float vy = cyImg - originY;

                            // æ—‹è½‰ -thetaï¼ˆè®“å…©çœ¼ç·šæ°´å¹³ï¼‰
                            float cosT = (float) Math.cos(theta), sinT = (float) Math.sin(theta);
                            float xr =  vx * cosT + vy * sinT;
                            float yr = -vx * sinT + vy * cosT;

                            // ç¸®æ”¾æ­£è¦åŒ–ï¼ˆé™¤ä»¥å…©çœ¼è·ï¼‰
                            if (dio > 1e-3f) {
                                xNorm = xr / dio;
                                yNorm = yr / dio;
                            }
                        }

                        // 7) å¯«å…¥ï¼šå‘¼å«ã€ŒèˆŒé ­å°ˆç”¨å¤šè¼‰ã€
                        dataRecorder.recordLandmarkData(
                                stateString,
                                detected,
                                bboxImg,
                                eyeLx, eyeLy, eyeRx, eyeRy,
                                browCx, browCy, noseX, noseY,
                                imgW, imgH,
                                System.currentTimeMillis(),
                                originX, originY,
                                theta,
                                dio,
                                cxImg, cyImg,
                                xNorm, yNorm
                        );
                    }
                });
            });

        } catch (Exception e) {
            Log.e(TAG, "è™•ç†èˆŒé ­æ¨¡å¼æ™‚ç™¼ç”ŸéŒ¯èª¤", e);
        }
    }

    // å˜´å”‡æ¨¡å¼ï¼šMediaPipe é—œéµé»
    private void handleLipMode(float[][] allPoints) {
        if (!shouldAcceptNewFrames()) return;
        //ç•«é¢é¡¯ç¤ºè‡‰éƒ¨é»
        overlayView.setAllFaceLandmarks(allPoints);
        //æ ¡æ­£ä¸­è·Ÿå‹•ä½œä¸­ç‹€æ…‹=>ç´€éŒ„
        if (!isTrainingCompleted && (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)) {
            String stateString = csvState();
            dataRecorder.recordLandmarkData(stateString, allPoints, null);
            //Log.d(TAG, "è¨˜éŒ„å˜´å”‡è³‡æ–™: " + stateString + ", é—œéµé»æ•¸é‡: " + allPoints.length);

            //Log.d(TAG_2, "è¨˜éŒ„å˜´å”‡è³‡æ–™: " + stateString + ", é—œéµé»æ•¸é‡: " + allPoints.length);
        }
    }

    // ä¸‹é¡æ¨¡å¼ï¼šMediaPipe é—œéµé»
    private void handleJawMode(float[][] allPoints) {
        if (!shouldAcceptNewFrames()) return;
        overlayView.setAllFaceLandmarks(allPoints);

        if (!isTrainingCompleted && (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)) {
            String stateString = csvState();
            dataRecorder.recordLandmarkData(stateString, allPoints, true);
            Log.d(TAG, "è¨˜ä¸‹é¡è³‡æ–™: " + stateString + ", é—œéµé»æ•¸é‡: " + allPoints.length);
        }
    }

    //è‡‰é °æ¨¡å¼
    private void handleCheeksMode(float[][] landmarks01, Bitmap mirroredBitmap, int img_w,int img_h) {
        if (!shouldAcceptNewFrames()) return;
        try {
            ensureCheekEngine();
            long ts = System.currentTimeMillis();

            cameraExecutor.execute(() -> {
                //CheekFlowEngine.FlowResult r = cheekEngine.process(mirroredBitmap, landmarks01, ts);

                if (!isTrainingCompleted &&
                        (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)){
//                        r.computedThisFrame) {
                    //è£œå„Ÿ
//                    org.opencv.core.Point li = r.vectors.get(CheekFlowEngine.Region.LEFT_INNER);
//                    org.opencv.core.Point ri = r.vectors.get(CheekFlowEngine.Region.RIGHT_INNER);
//                    //åŸå§‹
//                    org.opencv.core.Point liRaw = r.rawVectors.get(CheekFlowEngine.Region.LEFT_INNER);
//                    org.opencv.core.Point riRaw = r.rawVectors.get(CheekFlowEngine.Region.RIGHT_INNER);
//                    // å–å¾—ç‹€æ…‹å­—ä¸²ï¼ˆè·Ÿä½ å˜´å”‡/èˆŒé ­ä¸€è‡´ï¼‰
                    String stateString = csvState();

                    // æ”¹ç”¨æ›²ç‡
                    Log.e("FCA_Cheek_Curve", "imgW&H=="+img_w +","+img_h);
                    dataRecorder.recordLandmarkData(stateString, landmarks01,  img_w,  img_h);


                }
            });

        } catch (Exception e) {
            Log.e(TAG, "handleCheeksMode error", e);
        }
    }

    //è™•ç†æ™‚é–“é¡¯ç¤º
    private void handleFacePosition(boolean faceInside) {
        if (isTrainingCompleted) return;

        long currentTime = System.currentTimeMillis();

        switch (currentState) {
            case CALIBRATING:
                if (faceInside) {
                    if (calibrationStartTime == 0) {
                        calibrationStartTime = currentTime;
                        startCalibrationTimer();
                        demoStarted = false;
                        demoFinished = false;
                    }

                    CircleOverlayView.Status uiStatus = CircleOverlayView.Status.CALIBRATING;

                    if (demoEnabled && !demoFinished) {
                        if (!demoStarted) {
                            demoStarted = true;
                            demoStartMs = currentTime;
                        }
                        long d = currentTime - demoStartMs;

                        // çµ±ä¸€è¨­å®š cueText å¤§å°
                        if (cueText != null) {
                            cueText.setTextSize(android.util.TypedValue.COMPLEX_UNIT_SP, 32);
                        }

                        if (d < 4000) {
                            // 0~4sï¼šé»ƒæ¡† - æ”¾é¬†æ ¡æ­£
                            if (statusText != null) statusText.setVisibility(android.view.View.GONE);  // éš±è—

                            uiStatus = CircleOverlayView.Status.CALIBRATING;
                            if (statusText != null) statusText.setText("æ ¡æ­£ä¸­");
                            if (cueText != null) cueText.setText("æ”¾é¬†ï¼Œä¿æŒä¸å‹•");
                            isDemoPhase = false;

                        } else if (d < 8000) {
                            // 4~8sï¼šè—æ¡† - ç¤ºç¯„å‹•ä½œ
                            uiStatus = CircleOverlayView.Status.DEMO;
                            String zh = motionLabelZh(trainingLabel);
                            if (statusText != null) statusText.setText("æ ¡æ­£ä¸­");
                            if (cueText != null) cueText.setText("è«‹" + zh + "");
                            isDemoPhase = true;

                        } else if (d < 11000) {
                            // 8~11sï¼šé»ƒæ¡† - æº–å‚™é–‹å§‹
                            uiStatus = CircleOverlayView.Status.CALIBRATING;
                            if (statusText != null) statusText.setText("æ ¡æ­£ä¸­");
                            if (cueText != null) cueText.setText("æ”¾é¬†ï¼Œä¿æŒä¸å‹•");
                            isDemoPhase = false;

                        } else {
                            uiStatus = CircleOverlayView.Status.CALIBRATING;
                            demoFinished = true;
                        }
                    }

                    overlayView.setStatus(uiStatus);

                } else {
                    // é›¢é–‹åœ“æ¡†
                    resetCalibration();
                    overlayView.setStatus(CircleOverlayView.Status.OUT_OF_BOUND);
                    currentState = AppState.OUT_OF_BOUNDS;
                    demoStarted = false;
                    demoFinished = false;
                    if (statusText != null) statusText.setText("è¶…å‡ºé‚Šç•Œ");
                    if (cueText != null) cueText.setText("è«‹å›åˆ°åœ“æ¡†å…§");
                }
                break;

            case MAINTAINING:
                if (faceInside) {
                    if (maintainStartTime == 0) {
                        maintainStartTime = currentTime;
                        //åº•ä¸‹æ˜¯ç´€éŒ„çµ¦DBçš„å®Œæ•´è¨“ç·´é–‹å§‹æ™‚é–“
                        TraingStartTime = maintainStartTime;
                    }
                    overlayView.setStatus(CircleOverlayView.Status.OK);
                } else {
                    if (maintainStartTime > 0) {
                        maintainTotalTime += (currentTime - maintainStartTime);
                        maintainStartTime = 0;
                    }
                    resetToCalibration();
                }
                break;

            case OUT_OF_BOUNDS:
                if (faceInside) {
                    resetToCalibration();
                } else {
                    overlayView.setStatus(CircleOverlayView.Status.OUT_OF_BOUND);
                }
                break;
        }

        updateStatusDisplay();
        updateTimerDisplay();
    }




    // å…‰æµç›¸é—œ
    private void ensureCheekEngine() {
        if (cheekEngine == null) {
            CheekFlowEngine.Params pp = new CheekFlowEngine.Params();
            pp.targetWidth = 360;              // 0 = ä¸é™æ¡æ¨£ï¼›å»ºè­°å…ˆ 360
            pp.flowEvery = 2;                  // æ¯ 2 å¹€ç®—ä¸€æ¬¡
            pp.landmarksAreNormalized01 = true;
            pp.enableRigidCompensation = true; // æ–¹æ¡ˆAï¼šè£œå„Ÿå¾Œå¯«å…¥åŒæ¬„ä½
            pp.smoothAlpha = 0.25f;            // 0.2~0.4 å»ºè­°
            cheekEngine = new CheekFlowEngine(pp);
        }
    }

    //ç¢ºèªæ™‚é–“é¡¯ç¤ºæ–‡å­—
    private void startCalibrationTimer() {
        cancelTimers();
        Log.d(TAG_2, "ğŸŸ¡ é–‹å§‹æ ¡æ­£éšæ®µè¨ˆæ™‚å™¨");
        Log.d(TAG_3, "ğŸ¥ æ ¡æ­£é–‹å§‹ï¼Œå•Ÿå‹•éŒ„å½±");
        // ğŸ¥ åœ¨é€™è£¡é–‹å§‹éŒ„å½±ï¼
        if (ENABLE_VIDEO_RECORDING && videoCapture != null && currentRecording == null) {
            Log.d(TAG_3, "ğŸ¥ æ ¡æ­£é–‹å§‹ï¼Œå•Ÿå‹•éŒ„å½±");
            startVideoRecording();
        }

        calibrationTimer = () -> {
            Log.d(TAG, "ğŸŸ¡ æ ¡æ­£å®Œæˆï¼Œåˆ‡æ›åˆ°ç¶­æŒç‹€æ…‹");
            currentState = AppState.MAINTAINING;
            maintainStartTime = System.currentTimeMillis();
            overlayView.setStatus(CircleOverlayView.Status.OK);

            // â˜…â˜…â˜… å•Ÿå‹• 2 ç§’å°å¼•ï¼ˆä¾ trainingLabel æ›å­—ï¼‰
            startSimpleCue();
            startMaintainTimer();
            updateStatusDisplay();
            updateTimerDisplay();
        };
        mainHandler.postDelayed(calibrationTimer, CALIBRATION_TIME);
    }

    private void startMaintainTimer() {
        cancelTimers();
        Log.d(TAG, "ğŸŸ¢ é–‹å§‹ç¶­æŒéšæ®µè¨ˆæ™‚å™¨");

        maintainTimer = () -> {
            long currentTime = System.currentTimeMillis();
            long currentMaintainTime = maintainTotalTime;
            if (maintainStartTime > 0) {
                currentMaintainTime += (currentTime - maintainStartTime);
            }

            if (currentMaintainTime % 5000 < 100) {
                Log.d(TAG, String.format("â±ï¸ ç¶­æŒè¨ˆæ™‚æª¢æŸ¥ - ç´¯è¨ˆæ™‚é–“: %d ms / %d ms (%.1f%%)",
                        currentMaintainTime, MAINTAIN_TIME_TOTAL,
                        (currentMaintainTime * 100.0 / MAINTAIN_TIME_TOTAL)));
            }

            if (currentMaintainTime >= MAINTAIN_TIME_TOTAL) {
                Log.d(TAG, "âœ… ç¶­æŒæ™‚é–“é”æ¨™ï¼è¨“ç·´å®Œæˆ");
                Log.d(TAG_2, "âœ… ç¶­æŒæ™‚é–“é”æ¨™ï¼è¨“ç·´å®Œæˆ");
                completedTraining();
            } else {
                mainHandler.postDelayed(maintainTimer, 100);
            }
        };
        mainHandler.postDelayed(maintainTimer, 100);
    }

    private void startProgressUpdater() {
        progressUpdater = () -> {
            updateProgressBar();
            mainHandler.postDelayed(progressUpdater, PROGRESS_UPDATE_INTERVAL);
        };
        mainHandler.post(progressUpdater);
    }

    private void updateProgressBar() {
        if (isTrainingCompleted) {
            progressBar.setProgress(100);
            return;
        }

        int progress = 0;
        long currentTime = System.currentTimeMillis();

        switch (currentState) {
            case CALIBRATING:
                if (calibrationStartTime > 0) {
                    long elapsed = currentTime - calibrationStartTime;
                    progress = (int) ((elapsed * 100) / CALIBRATION_TIME);
                    progress = Math.min(progress, 100);
                }
                break;

            case MAINTAINING:
                long totalMaintainTime = maintainTotalTime;
                if (maintainStartTime > 0) {
                    totalMaintainTime += (currentTime - maintainStartTime);
                }
                progress = (int) ((totalMaintainTime * 100) / MAINTAIN_TIME_TOTAL);
                progress = Math.min(progress, 100);
                break;

            case OUT_OF_BOUNDS:
                break;
        }

        progressBar.setProgress(progress);
    }

    private void resetCalibration() {
        if (!isTrainingCompleted) {
            calibrationStartTime = 0;
            cancelTimers();
            currentState = AppState.CALIBRATING;
        }
    }

    private void resetToCalibration() {
        if (!isTrainingCompleted) {
            calibrationStartTime = 0;
            maintainStartTime = 0;
            cancelTimers();
            currentState = AppState.CALIBRATING;
        }
    }

    private void cancelTimers() {
        if (calibrationTimer != null) {
            mainHandler.removeCallbacks(calibrationTimer);
            calibrationTimer = null;
        }
        if (maintainTimer != null) {
            mainHandler.removeCallbacks(maintainTimer);
            maintainTimer = null;
        }
    }

    private void completedTraining() {
        stopSimpleCue();
        Log.d(TAG, " === è¨“ç·´å®Œæˆï¼é–‹å§‹å„²å­˜è³‡æ–™ ");
        Log.d(TAG_2, " ==å·²é€²å…¥compelete ");
        isTrainingCompleted = true;
        // ğŸ¥ åœæ­¢éŒ„å½±ï¼ˆæ­£å¸¸å®Œæˆï¼Œä¸åˆªé™¤ï¼‰
        if (currentRecording != null) {
            currentRecording.stop();
            currentRecording = null;
            Log.d(TAG, "âœ… éŒ„å½±å®Œæˆï¼Œå½±ç‰‡å·²ä¿å­˜");
        }
        cancelTimers();

        overlayView.setStatus(CircleOverlayView.Status.OK);
        updateStatusDisplay();
        updateTimerDisplay();

        Toast.makeText(this, " è¨“ç·´å®Œæˆï¼\næ­£åœ¨å„²å­˜æª”æ¡ˆä¸¦é€²è¡Œåˆ†æ...", Toast.LENGTH_LONG).show();

        //é€™é‚Šæœƒå…ˆå‘¼å«dataRecorder.saveToFileWithCallbacï¼Œåšé‹ç®—å®Œæˆå¾Œæœƒå¾dataRecorderé‚£é‚Šå‘¼å«ä¸‹é¢æ–¹æ³•onComplete
        //åº•ä¸‹new FaceDataRecorder.DataSaveCallback()ï¼Œå¥½åƒæ˜¯ä¸€å€‹callBackç‰©ä»¶åœ¨saveToFileWithCallbackæ–¹æ³•ç•¶åƒæ•¸
        dataRecorder.saveToFileWithCallback(new FaceDataRecorder.DataSaveCallback() {


            @Override
            public void onComplete(CSVMotioner.PyAnalysisResult res) {
                //20251002 : ç¾åœ¨è¦å¾é ç«¯å›å‚³æ”¹å›ä½£PYHONæœ¬åœ°å€¼
                Log.d(TAG, "âœ… æ¸¬è©¦å‚³æ•¸å€¼åˆ°Vercel_");
                //è®Šæ•¸å®£å‘Š
                final String payload = dataRecorder.exportLinesAsJson();
                final String csv = dataRecorder.getFileName();
                final String label0 = trainingLabel;
                final int target = 0;
                final int duration0 = MAINTAIN_TIME_TOTAL / 1000;

                Log.d("API_SEND", "âœ… ä¸Šå‚³CSVå…§å®¹::"+payload);
                Log.d("SEND_TO_PYTHONï¼Œçœ‹payloadè®Šæ•¸å°±çŸ¥é“å…§æ–‡", "âœ… ä¸Šå‚³CSVå…§å®¹::"+payload);
                Log.d("PYTHON RETURN REESULT", "âœ… å›å‚³å…§å®¹::"+payload);

                // æ”¹å‘¼å«Pythonå»è®€CSVæª”æ¡ˆ
                String label = label0;
                String ResMotionType = "";
                String curveJson = "";
                String TAB1 = "viewProblem";

                int actual   = 0;
                int duration = duration0;

                actual   = res.actionCount;
                duration = (int) res.totalActionTime;


                new Thread(() -> {
                    // æ”¹å‘¼å«Pythonå»è®€CSVæª”æ¡ˆ
                    String flabel = label0;
                    String fResMotionType = "";
                    String fcurveJson = "";
                    String fTAB1 = "viewProblem";

                    int factual   = 0;
                    int fduration = duration0;

                    factual   = res.actionCount;
                    fduration = (int) res.totalActionTime;

                    //å­˜æª”èˆ‡è·³é 
                    insertTrainingRecord(trainingLabel_String, factual, 6, fduration, csv,null);
                    runOnUiThread(() -> go(trainingLabel_String, 0, target, 0, csv, "test"));
                }).start();
                // æ£„ç”¨ : é€åˆ° APIï¼Œç­‰å›æ‡‰å¾Œå†è·³é ï¼›å¤±æ•—å°±ç”¨æœ¬åœ°çµæœ

//                OkHttpClient client = new OkHttpClient();
//                Request req = new Request.Builder()
//                        .url(API_URL) // ä½ ä¸Šé¢å·²ç¶“å®šç¾©å¥½çš„å¸¸æ•¸
//                        .post(RequestBody.create(payload, MediaType.parse("application/json; charset=utf-8")))
//                        .build();
//
//                client.newCall(req).enqueue(new okhttp3.Callback() {
//                    @Override public void onFailure(okhttp3.Call call, java.io.IOException e) {
//                        Log.e("API_RES", "âŒ API å¤±æ•—ï¼Œæ”¹ç”¨æœ¬åœ°çµæœ", e);
//                        runOnUiThread(() -> go(label0, result.totalPeaks, target, duration0, csv, null));
//                    }
//
//                    @Override public void onResponse(okhttp3.Call call, okhttp3.Response response) throws java.io.IOException {
//                        String body = (response.body() != null) ? response.body().string() : "";
//                        Log.d("API_RES", "âœ… API å›æ‡‰: " + body);

                        // å…ˆç”¨æœ¬åœ°å€¼ï¼Œè‹¥å›æ‡‰å«æ¬„ä½å°±è¦†å¯«
                        // â˜… å…ˆç”¨æœ¬åœ°å€¼ï¼›æœ‰å›æ‡‰å°±æŒ‰å‹•ä½œé¡å‹è¦†å¯«
//                        String label = label0;
//                        String ResMotionType = "";
//                        int actual   = result.totalPeaks;
//                        int duration = duration0;
//                        String curveJson = "";
//                        String TAB1 = "viewProblem";
//                        try {
//                            org.json.JSONObject obj = new org.json.JSONObject(body);
//                            org.json.JSONObject resultObj = obj.optJSONObject("result");
//                            Log.e(TAB1, "âœ… API JSON å›å‚³å®Œæ•´å…§å®¹: \n" + obj.toString(2));
//                            label = canonicalMotion(obj.optString("motion", label)); // æ­£è¦åŒ–
//
//                             ResMotionType = obj.optString("trainingType", ResMotionType);
//
//
//
//
//                            if ("POUT_LIPS".equals(ResMotionType)) {
//                                assert resultObj != null;
//                                actual   = resultObj.optInt("action_count", actual);
//                                duration = (int) Math.round(resultObj.optDouble("total_action_time", duration));
////                            }
//                              else if ("closeLip".equals(label)) {
////                                actual   = obj.optInt("close_count", actual);
////                                duration = (int) Math.round(obj.optDouble("total_close_time", duration));
//                            }else if ("SIP_LIPS".equals(ResMotionType)) {
//                                assert resultObj != null;
//                                actual   = resultObj.optInt("action_count", actual);
//                                duration = (int) Math.round(resultObj.optDouble("total_action_time", duration));
//                            }else if ("PUFF_CHEEK".equals(ResMotionType)) {
//                                assert resultObj != null;
//                                actual   = resultObj.optInt("action_count", actual);
//                                duration = (int) Math.round(resultObj.optDouble("total_action_time", duration));
//
//                                // å–å‡º curve
//                                JSONArray curveArray = resultObj.optJSONArray("curve");
//                                curveJson = (curveArray != null) ? curveArray.toString() : "[]";
//
//                                Log.e("IN PUFF_CHEEK", "actual=" + actual + ", duration=" + duration);
//                                Log.e("IN PUFF_CHEEK", "curveJson=" + curveJson);
//
//                            }
//                        } catch (Exception ignore) {
//                            Log.e(TAB1, "==æ²’æ‹¿åˆ°å€¼ï¼Œè·‘é€²ignore ======");
//                            /* é JSON å°±ä¿ç•™æœ¬åœ°å€¼ */ }
//
//
//                        final String fLabel = label;
//                        final int fActual = actual;
//                        final int fDuration = duration;
//                        final String apiJson = body;
//                        final String fCurveJson = curveJson;   // âœ… åŒ…æˆ final è®Šæ•¸
//                        // å¯«å®Œ DB å†è·³é 
//                        new Thread(() -> {
////                            Log.e(TAB1, "====== å‘¼å« insertTrainingRecord / go å‰çš„åƒæ•¸ ======");
////                            Log.e(TAB1, "fLabel: " + fLabel);
////                            Log.e(TAB1, "fActual: " + fActual);
////                            Log.e(TAB1, "target: " + target);
////                            Log.e(TAB1, "fDuration: " + fDuration);
////                            Log.e(TAB1, "csv: " + csv);
////                            Log.e(TAB1, "apiJson: " + apiJson);
////                            Log.e(TAB1, "trainingLabel_String: " + trainingLabel_String);
////                            Log.e(TAB1, "===========================================");
////
////                            //å­˜æª”èˆ‡è·³é 
////                            insertTrainingRecord(trainingLabel_String, fActual, target, fDuration, csv,fCurveJson);
//                            runOnUiThread(() -> go(trainingLabel_String, 0, target, 0, csv, "test"));
//                        }).start();
//                    }
//                });
            }


            @Override
            public void onError(String error) {
                Log.e(TAG, "âŒ å„²å­˜æˆ–åˆ†æå¤±æ•—: " + error);
                Toast.makeText(FaceCircleCheckerActivity.this, "è™•ç†å¤±æ•—: " + error, Toast.LENGTH_LONG).show();
                new Handler(Looper.getMainLooper()).postDelayed(() -> finish(), 3000);
            }
        });
    }

    //å€åŸŸ_æé†’æ”¾é¬†èˆ‡å‹•ä½œå°å¼•
    private String getReadableLabel() {
        if (trainingLabel == null) return "è¨“ç·´";
        switch (trainingLabel) {
            case "TONGUE_LEFT":   return "èˆŒé ­å·¦ç§»";
            case "TONGUE_RIGHT":  return "èˆŒé ­å³ç§»";
            case "TONGUE_FOWARD": // ä½ åŸç¨‹å¼æ‹¼çš„æ˜¯ FOWARD
            case "TONGUE_FORWARD":return "èˆŒé ­å‰ä¼¸";
            case "TONGUE_BACK":   return "èˆŒé ­å¾Œç¸®";
            case "TONGUE_UP":     return "èˆŒé ­ä¸ŠæŠ¬";
            case "TONGUE_DOWN":   return "èˆŒé ­ä¸‹å£“";
            case "PUFF_CHEEK":    return "é¼“èµ·è‡‰é °";
            case "REDUCE_CHEEK":  return "æ”¾é¬†è‡‰é °";
            case "JAW_LEFT":      return "ä¸‹é¡å·¦ç§»";
            case "JAW_RIGHT":     return "ä¸‹é¡å³ç§»";
            default:              return trainingLabel; // ä¿åº•ï¼šç›´æ¥é¡¯ç¤ºåŸå­—
        }
    }
    // é–‹å§‹ 2 ç§’å°å¼•ï¼šå‹•ä½œ â†’ æ”¾é¬† â†’ å‹•ä½œ â†’ æ”¾é¬†ï¼ˆå¾ªç’°ï¼‰
    private void startSimpleCue() {
        stopSimpleCue();      // ä¿éšªæ¸…ç†
        cueRunning = true;
        cueStep = 0;
        postNextCue(0);       // ç«‹åˆ»é€²ç¬¬ä¸€æ®µ
    }

    // åœæ­¢å°å¼•ï¼šåªç§»é™¤æˆ‘å€‘è‡ªå·±çš„ runnableï¼Œä¸å½±éŸ¿å…¶ä»–è¨ˆæ™‚å™¨
    private void stopSimpleCue() {
        cueRunning = false;
        if (cueRunnable != null && mainHandler != null) {
            mainHandler.removeCallbacks(cueRunnable);
            cueRunnable = null;
        }
    }

    // å®‰æ’ä¸‹ä¸€æ­¥ï¼ˆç”¨ if/else å¯«æ­» 2 ç§’ï¼‰ï¼Œä¸¦æ ¹æ“š trainingLabel æ›å­—
    //20251127 å…ˆå–æ¶ˆæ–‡å­—
    private void postNextCue(long delayMs) {
        if (mainHandler == null) return;
        final int segMs = Math.max(1, CUE_SEGMENT_SEC) * 1000;

        cueRunnable = () -> {
            // â˜… åŠ å…¥é€™å€‹æª¢æŸ¥ï¼šè¨“ç·´å®Œæˆå°±ä¸è¦å†æ›´æ–°
            if (!cueRunning || cueText == null || isTrainingCompleted) return;

            String zh = motionLabelZh(trainingLabel);
            cueText.setTextSize(android.util.TypedValue.COMPLEX_UNIT_SP, 32);

            if (cueStep % 2 == 0) {
                cueText.setText("ä¿æŒ " + zh);
            } else {
                cueText.setText("æ”¾é¬†");
            }

            cueStep++;

            // â˜… ä¹Ÿåœ¨é€™è£¡æª¢æŸ¥ä¸€æ¬¡
            if (!isTrainingCompleted) {
                mainHandler.postDelayed(() -> postNextCue(0), segMs);
            }
        };
        mainHandler.postDelayed(cueRunnable, delayMs);
    }



    private void onStartTraining() {
        if (trainingStarted) return;
        trainingStarted = true;
        Log.d(TAG_3, "âœ… é–‹å§‹éŒ„å½±æµç¨‹");

        // é–‹å§‹éŒ„å½±
        if (ENABLE_VIDEO_RECORDING && videoCapture != null) {
            startVideoRecording();
        }
        Log.d(TAG_2, "âœ… é–‹å§‹è¨“ç·´æµç¨‹");

        // ç‹€æ…‹æç¤º
        if (statusText != null) statusText.setText("è¨“ç·´ä¸­...");

        // 1) é–‹å§‹å£ä»¤å¾ªç’°ï¼ˆå‹•ä½œæç¤ºï¼‰
        cueRunning = true;
        cueStep = 0;
        postNextCue(0);


    }



    //ç½®é ‚ç‹€æ…‹èªªæ˜æ–‡å­—
    private void updateStatusDisplay() {
        if (statusText == null) return;

        statusText.setTextSize(android.util.TypedValue.COMPLEX_UNIT_SP, 18);

        if (isTrainingCompleted) {
            statusText.setText("å®Œæˆ");
            if (cueText != null) {
                cueText.setTextSize(android.util.TypedValue.COMPLEX_UNIT_SP, 32);
                cueText.setText("âœ… è¨“ç·´å®Œæˆï¼");
            }
        } else if (currentState == AppState.MAINTAINING) {
            statusText.setText("è¨“ç·´ä¸­");
        } else if (currentState == AppState.OUT_OF_BOUNDS) {
            statusText.setText("è¶…å‡ºé‚Šç•Œ");
        }
        // CALIBRATING åœ¨ handleFacePosition() è™•ç†
    }


    private void updateTimerDisplay() {
        if (timerText == null) return;

        if (isTrainingCompleted) {
            timerText.setText("âœ… å®Œæˆ");
            return;
        }

        long currentTime = System.currentTimeMillis();
        String timeText;

        switch (currentState) {
            case CALIBRATING:
                if (calibrationStartTime > 0) {
                    long elapsed = currentTime - calibrationStartTime;
                    long remaining = Math.max(0, CALIBRATION_TIME - elapsed);
                    timeText = String.format("â± %dç§’", (remaining / 1000) + 1);
                } else {
                    timeText = "â± 5ç§’";
                }
                break;

            case MAINTAINING:
                long totalMaintainTime = maintainTotalTime;
                if (maintainStartTime > 0) {
                    totalMaintainTime += (currentTime - maintainStartTime);
                }
                long remaining = Math.max(0, MAINTAIN_TIME_TOTAL - totalMaintainTime);
                timeText = String.format("â± %dç§’", remaining / 1000);
                break;

            case OUT_OF_BOUNDS:
            default:
                timeText = "â± --";
                break;
        }

        timerText.setText(timeText);
    }

    // å¹«æ‰‹ï¼šé—œé–‰ ExecutorServiceï¼ˆå¯é‡ç”¨ï¼‰
    private void awaitShutdown(java.util.concurrent.ExecutorService exec) {
        if (exec == null) return;
        try {
            exec.shutdownNow(); // ç«‹åˆ»ä¸­æ–·å°šæœªé–‹å§‹çš„èˆ‡å¯ä¸­æ–·çš„ä»»å‹™
            exec.awaitTermination(1500, java.util.concurrent.TimeUnit.MILLISECONDS); // ç­‰ä¸€ä¸‹æ”¶å°¾
        } catch (InterruptedException ignored) {
        }
    }

    // 2) æŠŠä»£è™Ÿè®Šä¸­æ–‡é¡¯ç¤ºæ–‡å­—
    private String motionLabelZh(String label) {
        if (label == null) return "å‹•ä½œ";

        switch (label) {
            // å˜´å”‡
            case "POUT_LIPS":
            case "poutLip":
                return "å˜Ÿå˜´";
            case "SIP_LIPS":
            case "closeLip":
                return "æŠ¿å˜´";

            // èˆŒé ­
            case "TONGUE_LEFT":     return "èˆŒé ­å¾€å·¦";
            case "TONGUE_RIGHT":    return "èˆŒé ­å¾€å³";
            case "TONGUE_FOWARD":
            case "TONGUE_FORWARD":  return "èˆŒé ­å‰ä¼¸";
            case "TONGUE_BACK":     return "èˆŒé ­å¾Œç¸®";
            case "TONGUE_UP":       return "èˆŒé ­ä¸ŠæŠ¬";
            case "TONGUE_DOWN":     return "èˆŒé ­ä¸‹å£“";

            // è‡‰é °
            case "PUFF_CHEEK":      return "é¼“è‡‰é °";
            case "REDUCE_CHEEK":    return "ç¸®è‡‰é °";



            default:                return "å‹•ä½œ";
        }
    }
    // â˜… æ–°å¢ï¼šæŠŠå„ç¨®å¯«æ³•æ­¸ä¸€æˆ poutLip / closeLip
    private String canonicalMotion(String s) {
        if (s == null) return "";
        String x = s.trim().toLowerCase(java.util.Locale.ROOT);
        if (x.contains("pout"))  return "poutLip";
        if (x.contains("close") || x.contains("sip") || x.contains("slip") || x.contains("æŠ¿"))
            return "closeLip";
        return s;
    }

    // æ–°å¢è¨“ç·´çµæœåˆ°DB
    private void insertTrainingRecord(String label, int achieved, int target, int duration, String csv,String curveJson) {
        long currentTime = System.currentTimeMillis();

        User loggedInUser = AppDatabase.getInstance(this).userDao().findLoggedInOne();
        String username = (loggedInUser != null)?loggedInUser.userId : "guest";
        long createAt = maintainStartTime;
        long finishAt = maintainStartTime + maintainTotalTime;
        long targetTimes = MAINTAIN_TIME_TOTAL/1000/CUE_SEGMENT_SEC/2;
        int achievedTimes = achieved;
        long durationTime = duration;
        String analysisType = label;

        //å…ˆç”±æ¯«ç§’è½‰æˆ"yyyy-MM-dd HH:mm:ss"
        Date date = new Date(createAt);
        SimpleDateFormat sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss");
        String readableTime = sdf.format(date);

        String trainingID = username+"_"+label+"_"+readableTime;
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "==========================================");
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "username: " + username);
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "createAt: " + createAt + " (" + sdf.format(new Date(createAt)) + ")");
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "finishAt: " + finishAt + " (" + sdf.format(new Date(finishAt)) + ")");
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "targetTimes: " + targetTimes);
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "achievedTimes: " + achievedTimes);
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "durationTime: " + durationTime);
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "analysisType: " + analysisType);
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "trainingID: " + trainingID);
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "readableTime: " + readableTime);
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "curveJson: " + curveJson);
        Log.e("å¯«å…¥é‹å‹•ç´€éŒ„ä¸­çœ‹åƒæ•¸", "==========================================");
        TrainingHistory history = new TrainingHistory(
                trainingID,
                label,
                maintainStartTime,  // createAt
                currentTime,        // finishAt
                target,
                achieved,
                duration,
                curveJson
        );
        new Thread(() -> {
            AppDatabase.getInstance(this).trainingHistoryDao().insert(history);
            Log.d(TAG, "âœ… è¨“ç·´è¨˜éŒ„å·²å¯«å…¥è³‡æ–™åº«");
        }).start();
    }


    /**
     * æŠŠ JSON å‚³åˆ° Vercel API
     * @param json ä½ è¦é€å‡ºçš„ JSON å­—ä¸²
     */
    private static final String API_URL = "https://wavecut-production.up.railway.app/"; // Railway æ ¹è·¯å¾‘



    // 2) ç°¡å–®çš„è·³é æ–¹æ³•ï¼ˆå…± 10 è¡Œï¼‰
    // â˜… ç”¨æ­£è¦åŒ–å¾Œçš„åç¨±æ±ºå®šè¦å¡å“ªçµ„é™£åˆ—åˆ° Intent
    //To do ... DEBUG CSVè¦å»å¼„å¾Œç«¯çœ‹DEBIGåˆ†æè·Ÿæ¿¾æ³¢æ€éº¼åšï¼Œèˆ¬å»railway API
    private void go(String label, int actual, int target, int durationSec, String csv, String apiJson) {
        String canon = canonicalMotion(label);
        Log.e("GO METHOD", "åœ¨GOæ–¹æ³•è·³è½‰é é¢ä¸­..");

        //åŸæœ¬çš„å…ˆæ”¹FIGMAçš„çœ‹çœ‹
        //Intent it = new Intent(FaceCircleCheckerActivity.this, AnalysisResultActivity.class);
        Intent it = new Intent(FaceCircleCheckerActivity.this, TrainingResultActivity.class);
        it.putExtra("training_label", canon);
        it.putExtra("actual_count", actual);
        it.putExtra("target_count", 5);
        it.putExtra("training_duration", durationSec);
        it.putExtra("csv_file_name", csv);
        if (apiJson != null && !apiJson.isEmpty()) it.putExtra("api_response_json", apiJson);

        if ("poutLip".equals(canon)) {
            double[] times  = dataRecorder.getTimeSecondsArrayForRatio();
            double[] ratios = dataRecorder.getHeightWidthRatioArray();
            it.putExtra("ratio_times", times);
            it.putExtra("ratio_values", ratios);
            android.util.Log.d("GO", "poutLip ratio_times=" + java.util.Arrays.toString(times));
            android.util.Log.d("GO", "poutLip ratio_values=" + java.util.Arrays.toString(ratios));

        } else if ("closeLip".equals(canon)) {
            double[][] tv = dataRecorder.exportLipTimeAndTotal();
            it.putExtra("lip_times",  tv[0]);
            it.putExtra("lip_totals", tv[1]);
            android.util.Log.d("GO", "closeLip lip_times=" + java.util.Arrays.toString(tv[0]));
            android.util.Log.d("GO", "closeLip lip_totals=" + java.util.Arrays.toString(tv[1]));
        }

        startActivity(it);
        finish();
    }

    /**
     * ğŸ¥ é–‹å§‹éŒ„å½±
     */
    private void startVideoRecording() {
        if (videoCapture == null) {
            Log.e(TAG_3, "âŒ VideoCapture æœªåˆå§‹åŒ–");
            return;
        }

        try {
//            SimpleDateFormat sdf = new SimpleDateFormat("yyyyMMdd_HHmmss", Locale.getDefault());
//            String timestamp = sdf.format(new Date());
//            String fileName = "Training_" + trainingLabel + "_" + timestamp + ".mp4";
//
//            File videoFile = new File(getExternalFilesDir(null), fileName);
//            videoFilePath = videoFile.getAbsolutePath();

            SimpleDateFormat sdf = new SimpleDateFormat("yyyyMMdd_HHmmss", Locale.getDefault());
            String timestamp = sdf.format(new Date());

// å¾ SharedPreferences æ‹¿ userId
            SharedPreferences prefs =
                    getSharedPreferences("user_prefs", MODE_PRIVATE);
            String userId = prefs.getString("current_user_id", "guest");

// åœ¨æª”åå‰é¢åŠ  userId
            String fileName = userId + "_Training_" + trainingLabel + "_" + timestamp + ".mp4";

            File videoFile = new File(getExternalFilesDir(null), fileName);


            FileOutputOptions outputOptions = new FileOutputOptions.Builder(videoFile).build();

            currentRecording = videoCapture.getOutput()
                    .prepareRecording(this, outputOptions)
                    .start(ContextCompat.getMainExecutor(this), videoRecordEvent -> {
                        if (videoRecordEvent instanceof VideoRecordEvent.Finalize) {
                            VideoRecordEvent.Finalize finalizeEvent = (VideoRecordEvent.Finalize) videoRecordEvent;
                            if (!finalizeEvent.hasError()) {
                                Log.d(TAG_3, "âœ… å½±ç‰‡å·²ä¿å­˜: " + videoFilePath);
                            } else {
                                Log.e(TAG_3, "âŒ å½±ç‰‡éŒ„è£½å¤±æ•—: " + finalizeEvent.getError());
                            }
                        }
                    });

            Log.d(TAG_3, "ğŸ¥ é–‹å§‹éŒ„å½±: " + fileName);
        } catch (Exception e) {
            Log.e(TAG_3, "âŒ é–‹å§‹éŒ„å½±å¤±æ•—", e);
        }
    }

    /**
     * ğŸ¥ åœæ­¢éŒ„å½±
     */
    private void stopVideoRecording() {
        if (currentRecording != null) {
            currentRecording.stop();
            currentRecording = null;
            Log.d(TAG_3, "ğŸ¥ åœæ­¢éŒ„å½±");
        }
    }

    private String csvState() {
        CircleOverlayView.Status ui = (overlayView != null) ? overlayView.getStatus() : null;
        if (ui == CircleOverlayView.Status.DEMO) return "DEMO";
        if (currentState == AppState.CALIBRATING) return "CALIBRATING";
        if (currentState == AppState.MAINTAINING) return "MAINTAINING";
        if (ui == CircleOverlayView.Status.OUT_OF_BOUND) return "OUT_OF_BOUND";
        return "UNKNOWN";
    }




}
