package com.example.rehabilitationapp.ui.facecheck;

import android.Manifest;
import android.content.Intent;
import android.content.pm.PackageManager;
import android.graphics.Bitmap;
import android.graphics.BitmapFactory;
import android.graphics.ImageFormat;
import android.graphics.Matrix;
import android.graphics.Rect;
import android.graphics.YuvImage;
import android.os.Bundle;
import android.os.Handler;
import android.os.Looper;
import android.util.Log;
import android.widget.ProgressBar;
import android.widget.TextView;
import android.widget.Toast;

import androidx.annotation.NonNull;
import androidx.appcompat.app.AppCompatActivity;
import androidx.camera.core.CameraSelector;
import androidx.camera.core.ImageAnalysis;
import androidx.camera.core.ImageProxy;
import androidx.camera.core.Preview;
import androidx.camera.lifecycle.ProcessCameraProvider;
import androidx.camera.view.PreviewView;
import androidx.core.app.ActivityCompat;
import androidx.core.content.ContextCompat;

import com.example.rehabilitationapp.R;
import com.example.rehabilitationapp.ui.results.AnalysisResultActivity;
import com.example.rehabilitationapp.ui.analysis.CSVPeakAnalyzer;
import com.google.common.util.concurrent.ListenableFuture;
import com.google.mediapipe.framework.image.BitmapImageBuilder;
import com.google.mediapipe.framework.image.MPImage;
import com.google.mediapipe.tasks.core.BaseOptions;
import com.google.mediapipe.tasks.vision.core.RunningMode;
import com.google.mediapipe.tasks.vision.facelandmarker.FaceLandmarker;
import com.google.mediapipe.tasks.vision.facelandmarker.FaceLandmarkerResult;

import java.io.ByteArrayOutputStream;
import java.nio.ByteBuffer;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.ExecutorService;
import java.util.concurrent.Executors;

//å…‰æµ
import org.opencv.android.OpenCVLoader;
import org.opencv.core.Point;

public class FaceCircleCheckerActivity extends AppCompatActivity {

    // ç›¸æ©Ÿæ¬Šé™ç”¨
    private static final int PERMISSION_REQUEST_CODE = 123;
    // LOG çš„ Tag
    private static final String TAG = "FaceCircleChecker";

    // finalè™•ç†åŸ·è¡Œç·’ï¼Œå¾…ç¾æœ‰Threadè‡ªè¡Œå®Œæˆå¾Œå†é—œé–‰
    private volatile boolean isStopping = false;
    // è®“æäº¤ä»»å‹™å‰éƒ½èƒ½å®ˆé–€ï¼Œä¾‹å¦‚åœ¨ handleCheeksMode() / å½±æ ¼è™•ç†å…¥å£ï¼š
    private boolean shouldAcceptNewFrames() { return !isStopping; }


    // è¨ˆæ™‚å¸¸æ•¸
    private static final int CALIBRATION_TIME = 5000;         // 5 ç§’æ ¡æ­£
    private static final int MAINTAIN_TIME_TOTAL = 30000;     // 30 ç§’ç¶­æŒ
    private static final int PROGRESS_UPDATE_INTERVAL = 50;   // é€²åº¦æ¢æ›´æ–°é–“éš”

    // â˜…â˜…â˜… é »ç‡æ§åˆ¶ï¼ˆå¯è‡ªè¡Œèª¿æ•´ï¼‰â˜…â˜…â˜…
    private static final int FACE_MESH_EVERY = 5;   // æ¯ 5 å¹€æ›´æ–°ä¸€æ¬¡ã€Œå˜´å·´ ROIã€
    private static final int YOLO_EVERY      = 3;  // æ¯ 3 å¹€è·‘ä¸€æ¬¡ YOLO

    // android.camera.core
    private PreviewView cameraView;
    private FaceLandmarker faceLandmarker;
    private ProcessCameraProvider cameraProvider;

    // åŸ·è¡Œç·’
    private ExecutorService cameraExecutor;
    private ExecutorService yoloExecutor;
    // UI
    private CircleOverlayView overlayView;
    private TextView statusText;
    private TextView timerText;
    private ProgressBar progressBar;

    // è¨“ç·´è³‡è¨Š
    private String trainingLabel = "è¨“ç·´";
    private int trainingType = -1;

    // è¨˜éŒ„å™¨
    private FaceDataRecorder dataRecorder;

    // YOLO
    private TongueYoloDetector tongueDetector;
    private boolean isYoloEnabled = false;

    // è‡‰é °å…‰æµ
    private CheekFlowEngine cheekEngine;

    private void ensureCheekEngine() {
        if (cheekEngine == null) {
            CheekFlowEngine.Params pp = new CheekFlowEngine.Params();
            pp.targetWidth = 360;              // 0 = ä¸é™æ¡æ¨£ï¼›å»ºè­°å…ˆ 360
            pp.flowEvery = 2;                  // æ¯ 2 å¹€ç®—ä¸€æ¬¡
            pp.landmarksAreNormalized01 = true;
            pp.enableRigidCompensation = true; // æ–¹æ¡ˆAï¼šè£œå„Ÿå¾Œå¯«å…¥åŒæ¬„ä½
            pp.smoothAlpha = 0.25f;            // 0.2~0.4 å»ºè­°
            cheekEngine = new CheekFlowEngine(pp);
        }
    }

    // å¹€è¨ˆæ•¸èˆ‡çµ±è¨ˆ
    private int frameId = 0;
    private long firstMetricTime = 0;

    // ROI å¿«å–ï¼ˆOverlay/Bitmap å…©å¥—åº§æ¨™ç³»ï¼‰
    private Rect lastOverlayRoi = null;
    private Rect lastBitmapRoi  = null;

    // ç‹€æ…‹ç®¡ç†
    private enum AppState { CALIBRATING, MAINTAINING, OUT_OF_BOUNDS }
    private AppState currentState = AppState.CALIBRATING;

    // ä¸»åŸ·è¡Œç·’ handler èˆ‡è¨ˆæ™‚ä»»å‹™
    private Handler mainHandler;
    private Runnable calibrationTimer;
    private Runnable maintainTimer;
    private Runnable progressUpdater;

    // è¨ˆæ™‚
    private long calibrationStartTime = 0;
    private long maintainStartTime = 0;
    private long maintainTotalTime = 0;
    private boolean isTrainingCompleted = false;

    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_face_circle_checker);

        //è‡‰é °å…‰æµä½¿ç”¨
        if (!OpenCVLoader.initDebug()) {
            Log.e(TAG, "âŒ OpenCVLoader.initDebug() å¤±æ•—");
        } else {
            Log.d(TAG, "âœ… OpenCV åˆå§‹åŒ–æˆåŠŸ");
        }

        trainingType = getIntent().getIntExtra("training_type", -1);
        //trainingLabel = getIntent().getStringExtra("training_label");
        //æ”¹å‹•ä½œï¼Œæ‹¿åˆ°DBçš„anlaystType
        trainingLabel = getIntent().getStringExtra("training_type");
        if (trainingLabel == null) trainingLabel = "è¨“ç·´";
        Log.d(TAG, "æ¥æ”¶åˆ°è¨“ç·´é¡å‹: " + trainingType + ", æ¨™ç±¤: " + trainingLabel);

        if ("èˆŒé ­".equals(trainingLabel) ||
                "TONGUE_LEFT".equals(trainingLabel) ||
                "TONGUE_RIGHT".equals(trainingLabel) ||
                "TONGUE_FOWARD".equals(trainingLabel) ||
                "TONGUE_BACK".equals(trainingLabel) ||
                "TONGUE_UP".equals(trainingLabel) ||
                "TONGUE_DOWN".equals(trainingLabel)) {
            initializeTongueDetector();
            Log.d(TAG, "âœ… èˆŒé ­æ¨¡å¼ï¼šä½¿ç”¨ MediaPipe é—œéµé»é¡¯ç¤ºèˆ‡å•Ÿç”¨ YOLO æª¢æ¸¬ + YOLO é¡¯ç¤º");
        }
        else {
            Log.d(TAG, "âœ… éé ­æ¨¡å¼ï¼šä½¿ç”¨ MediaPipe é—œéµé»é¡¯ç¤º");
        }

        dataRecorder = new FaceDataRecorder(this, trainingLabel, trainingType);
        Log.d(TAG, "è³‡æ–™è¨˜éŒ„å™¨åˆå§‹åŒ–å®Œæˆ");

        cameraView = findViewById(R.id.camera_view);
        overlayView = findViewById(R.id.overlay_view);
        statusText = findViewById(R.id.status_text);
        timerText = findViewById(R.id.timer_text);
        progressBar = findViewById(R.id.progress_bar);

        if ("èˆŒé ­".equals(trainingLabel) ||
                "TONGUE_LEFT".equals(trainingLabel) ||
                "TONGUE_RIGHT".equals(trainingLabel) ||
                "TONGUE_FOWARD".equals(trainingLabel) ||
                "TONGUE_BACK".equals(trainingLabel) ||
                "TONGUE_UP".equals(trainingLabel) ||
                "TONGUE_DOWN".equals(trainingLabel)) {
            overlayView.setDisplayMode(CircleOverlayView.DisplayMode.YOLO_DETECTION);
        } else {
            overlayView.setDisplayMode(CircleOverlayView.DisplayMode.LANDMARKS);
        }
        //Threadæ§åˆ¶å™¨åˆå§‹åŒ–
        cameraExecutor = Executors.newSingleThreadExecutor();//è™•ç†åœ–åƒ
        yoloExecutor = Executors.newSingleThreadExecutor(); //è™•ç†YOLO
        mainHandler = new Handler(Looper.getMainLooper());

        testCameraPermission();
        setupFaceLandmarker();
        initializeUI();

        if (checkCameraPermission()) {
            startCamera();
        } else {
            requestCameraPermission();
        }
    }

    // åˆå§‹åŒ–èˆŒé ­æª¢æ¸¬å™¨
    private void initializeTongueDetector() {
        try {
            tongueDetector = new TongueYoloDetector(this);
            isYoloEnabled = tongueDetector.isInitialized();
            if (!isYoloEnabled) {
                Log.e(TAG, "âŒ èˆŒé ­æª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—");
                Toast.makeText(this, "èˆŒé ­æª¢æ¸¬å™¨åˆå§‹åŒ–å¤±æ•—ï¼Œå°‡ä½¿ç”¨ä¸€èˆ¬æ¨¡å¼", Toast.LENGTH_SHORT).show();
            }
        } catch (Exception e) {
            Log.e(TAG, "âŒ èˆŒé ­æª¢æ¸¬å™¨åˆå§‹åŒ–éŒ¯èª¤: " + e.getMessage());
            isYoloEnabled = false;
            Toast.makeText(this, "èˆŒé ­æª¢æ¸¬å™¨è¼‰å…¥å¤±æ•—ï¼š" + e.getMessage(), Toast.LENGTH_LONG).show();
        }
    }

    private void initializeUI() {
        progressBar.setMax(100);
        progressBar.setProgress(0);
        updateStatusDisplay();
        updateTimerDisplay();
        startProgressUpdater();
    }

    // åˆå§‹åŒ– FaceLandmarker
    private void setupFaceLandmarker() {
        try {
            Log.d(TAG, "try to FaceLandmarker åˆå§‹åŒ–");
            FaceLandmarker.FaceLandmarkerOptions options = FaceLandmarker.FaceLandmarkerOptions.builder()
                    .setBaseOptions(BaseOptions.builder()
                            .setModelAssetPath("face_landmarker.task")
                            .build())
                    .setRunningMode(RunningMode.IMAGE)
                    .setNumFaces(1)
                    .build();
            faceLandmarker = FaceLandmarker.createFromOptions(this, options);
            Log.d(TAG, "FaceLandmarker åˆå§‹åŒ–æˆåŠŸ");
        } catch (Exception e) {
            Log.e(TAG, "FaceLandmarker åˆå§‹åŒ–éŒ¯èª¤: " + e.getMessage());
        }
    }

    private boolean checkCameraPermission() {
        return ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA)
                == PackageManager.PERMISSION_GRANTED;
    }

    private void requestCameraPermission() {
        ActivityCompat.requestPermissions(this, new String[]{Manifest.permission.CAMERA}, PERMISSION_REQUEST_CODE);
        Log.d("FaceCircleCheckerActivity","in to requestCameraPermission");
    }

    @Override
    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults);
        if (requestCode == PERMISSION_REQUEST_CODE) {
            if (grantResults.length > 0 && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                startCamera();
            } else {
                Toast.makeText(this, "éœ€è¦ç›¸æ©Ÿæ¬Šé™æ‰èƒ½ä½¿ç”¨æ­¤åŠŸèƒ½", Toast.LENGTH_LONG).show();
                finish();
            }
        }
    }

    private void startCamera() {
        ListenableFuture<ProcessCameraProvider> cameraProviderFuture = ProcessCameraProvider.getInstance(this);
        cameraProviderFuture.addListener(() -> {
            try {
                cameraProvider = cameraProviderFuture.get();
                bindCameraUseCases();
            } catch (ExecutionException | InterruptedException e) {
                Log.e(TAG, "ç›¸æ©Ÿåˆå§‹åŒ–å¤±æ•—", e);
                Toast.makeText(this, "ç›¸æ©Ÿåˆå§‹åŒ–å¤±æ•—", Toast.LENGTH_SHORT).show();
            }
        }, ContextCompat.getMainExecutor(this));
    }

    private void bindCameraUseCases() {
        Preview preview = new Preview.Builder().build();
        preview.setSurfaceProvider(cameraView.getSurfaceProvider());

        ImageAnalysis imageAnalysis = new ImageAnalysis.Builder()
                .setBackpressureStrategy(ImageAnalysis.STRATEGY_KEEP_ONLY_LATEST)
                .build();
        imageAnalysis.setAnalyzer(cameraExecutor, this::analyzeImage);

        CameraSelector cameraSelector = CameraSelector.DEFAULT_FRONT_CAMERA;

        try {
            cameraProvider.unbindAll();
            cameraProvider.bindToLifecycle(this, cameraSelector, preview, imageAnalysis);
            Log.d(TAG, "ç›¸æ©Ÿç¶å®šæˆåŠŸ");
        } catch (Exception e) {
            Log.e(TAG, "ç›¸æ©Ÿç¶å®šå¤±æ•—", e);
            Toast.makeText(this, "ç›¸æ©Ÿå•Ÿå‹•å¤±æ•—", Toast.LENGTH_SHORT).show();
        }
    }

    // åœ–åƒåˆ†æ
    private void analyzeImage(@NonNull ImageProxy imageProxy) {
        if (faceLandmarker == null) {
            imageProxy.close();
            return;
        }

        try {
            int rotationDegrees = imageProxy.getImageInfo().getRotationDegrees();
            Bitmap rawBitmap = imageProxyToBitmap(imageProxy);
            if (rawBitmap != null) {
                Bitmap rotatedBitmap = rotateBitmap(rawBitmap, rotationDegrees);
                Bitmap mirroredBitmap = mirrorBitmap(rotatedBitmap);

                MPImage mpImage = new BitmapImageBuilder(mirroredBitmap).build();
                FaceLandmarkerResult result = faceLandmarker.detect(mpImage);

                if (result != null && !result.faceLandmarks().isEmpty()) {
                    Log.d(TAG, "æª¢æ¸¬åˆ°äººè‡‰ï¼Œé—œéµé»æ•¸é‡: " + result.faceLandmarks().get(0).size());
                }
                checkFacePosition(result, mirroredBitmap.getWidth(), mirroredBitmap.getHeight(), mirroredBitmap);

                new Handler(Looper.getMainLooper()).postDelayed(() -> {
                    rawBitmap.recycle();
                    if (rotatedBitmap != rawBitmap) rotatedBitmap.recycle();
                    // mirroredBitmap äº¤ç”± GC
                }, 100);
            }
        } catch (Exception e) {
            Log.e(TAG, "åœ–åƒåˆ†æéŒ¯èª¤", e);
        } finally {
            // â­ æ¯å¹€çµæŸè‡ªå¢ï¼ˆçµ±ä¸€å¹€ç¯€å¥ï¼‰
            frameId++;
            imageProxy.close();
        }
    }

    private Bitmap rotateBitmap(Bitmap original, int degrees) {
        if (degrees == 0) return original;
        Matrix matrix = new Matrix();
        matrix.postRotate(degrees);
        return Bitmap.createBitmap(original, 0, 0, original.getWidth(), original.getHeight(), matrix, true);
    }

    private Bitmap mirrorBitmap(Bitmap original) {
        Matrix matrix = new Matrix();
        matrix.preScale(-1.0f, 1.0f);
        return Bitmap.createBitmap(original, 0, 0, original.getWidth(), original.getHeight(), matrix, false);
    }

    private Bitmap imageProxyToBitmap(@NonNull ImageProxy imageProxy) {
        try {
            ImageProxy.PlaneProxy[] planes = imageProxy.getPlanes();
            ByteBuffer yBuffer = planes[0].getBuffer();
            ByteBuffer uBuffer = planes[1].getBuffer();
            ByteBuffer vBuffer = planes[2].getBuffer();

            int ySize = yBuffer.remaining();
            int uSize = uBuffer.remaining();
            int vSize = vBuffer.remaining();

            byte[] nv21 = new byte[ySize + uSize + vSize];
            yBuffer.get(nv21, 0, ySize);

            byte[] uvPixelBuffer = new byte[uSize + vSize];
            vBuffer.get(uvPixelBuffer, 0, vSize);
            uBuffer.get(uvPixelBuffer, vSize, uSize);

            int uvPixelCount = 0;
            for (int i = ySize; i < nv21.length; i += 2) {
                nv21[i] = uvPixelBuffer[uvPixelCount];
                nv21[i + 1] = uvPixelBuffer[uvPixelCount + 1];
                uvPixelCount += 2;
            }

            YuvImage yuvImage = new YuvImage(nv21, ImageFormat.NV21,
                    imageProxy.getWidth(), imageProxy.getHeight(), null);
            ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
            yuvImage.compressToJpeg(new Rect(0, 0,
                    imageProxy.getWidth(), imageProxy.getHeight()), 100, outputStream);
            byte[] imageBytes = outputStream.toByteArray();

            return BitmapFactory.decodeByteArray(imageBytes, 0, imageBytes.length);

        } catch (Exception e) {
            Log.e(TAG, "ImageProxyè½‰æ›éŒ¯èª¤", e);
            return null;
        }
    }


    /**
     * å°‡ allPoints è½‰æˆã€ŒBitmap åƒç´ åº§æ¨™ã€ã€‚
     * - è‹¥çœ‹èµ·ä¾†æ˜¯ normalized(0~1) â†’ ä¹˜ä¸Š imgW/imgHã€‚
     * - å¦å‰‡è¦–ç‚º Overlay åº§æ¨™ â†’ ä¾ç­‰æ¯”ç¸®æ”¾+ç½®ä¸­æ¨¡å‹åæ¨å› Bitmap åƒç´ ã€‚
     */
    private float[][] toBitmapPixels(float[][] ptsIn,
                                     int imgW, int imgH,
                                     int overlayW, int overlayH) {
        float[][] out = new float[ptsIn.length][2];

        // ç²—æª¢ï¼šæŠ½æ¨£å‰20é»ï¼Œæœ‰ â‰¥70% è½åœ¨[0,1] å°±ç•¶ normalized
        int sample = Math.min(20, ptsIn.length), count01 = 0;
        for (int i = 0; i < sample; i++) {
            float x = ptsIn[i][0], y = ptsIn[i][1];
            if (x >= 0f && x <= 1f && y >= 0f && y <= 1f) count01++;
        }
        boolean looksNormalized = (count01 >= sample * 0.7f);

        if (looksNormalized) {
            for (int i = 0; i < ptsIn.length; i++) {
                out[i][0] = ptsIn[i][0] * imgW;
                out[i][1] = ptsIn[i][1] * imgH;
            }
            return out;
        }

        // Overlayâ†’Bitmap åè§£ï¼ˆview = img*scale + offsetï¼‰
        float scale = Math.min((float) overlayW / imgW, (float) overlayH / imgH);
        float offX = (overlayW - imgW * scale) / 2f;
        float offY = (overlayH - imgH * scale) / 2f;

        for (int i = 0; i < ptsIn.length; i++) {
            float vx = ptsIn[i][0], vy = ptsIn[i][1];
            out[i][0] = (vx - offX) / scale;
            out[i][1] = (vy - offY) / scale;
        }
        return out;
    }

    // åŠ å…¥ YOLO æ•´åˆ
    private void checkFacePosition(FaceLandmarkerResult result, int bitmapWidth, int bitmapHeight, Bitmap mirroredBitmap) {
        boolean faceDetected = result != null && !result.faceLandmarks().isEmpty();

        if (faceDetected) {
            try {
                runOnUiThread(() -> {
                    int overlayWidth = overlayView.getWidth();
                    int overlayHeight = overlayView.getHeight();

                    if (overlayWidth > 0 && overlayHeight > 0) {
                        float inputAspect = 480f / 640f; // Bitmap å¯¬é«˜æ¯”
                        float viewAspect = overlayWidth / (float) overlayHeight; // Overlay å¯¬é«˜æ¯”
                        float scaleX = inputAspect / viewAspect;

                        int landmarkCount = result.faceLandmarks().get(0).size();
                        float[][] landmarks01 = new float[landmarkCount][2]; // 0~1;//æ­£è¦åŒ–åŸå§‹åœ–åƒ
                        float[][] allPoints = new float[landmarkCount][2]; // 0~1;//è®Šå½¢æ¯”ä¾‹ï¼Œé¡¯ç¤ºç”¨åœ–åƒ

                        for (int i = 0; i < landmarkCount; i++) {
                            float x = result.faceLandmarks().get(0).get(i).x();
                            float y = result.faceLandmarks().get(0).get(i).y();

                            // å­˜ä¸€ä»½åŸå§‹ 0~1ï¼ˆçµ¦ CheekFlowEngine ç”¨ï¼‰
                            landmarks01[i][0] = x;
                            landmarks01[i][1] = y;
                            // é€™ä»½æ˜¯çµ¦ overlay ç•«é¢ï¼šåš X æ¯”ä¾‹è£œå„Ÿå¾Œè½‰åƒç´ 
                            x = (x - 0.5f) * scaleX + 0.5f;
                            allPoints[i][0] = x * overlayWidth;
                            allPoints[i][1] = y * overlayHeight;
                        }

                        if (("èˆŒé ­".equals(trainingLabel) ||
                                "TONGUE_LEFT".equals(trainingLabel) ||
                                "TONGUE_RIGHT".equals(trainingLabel) ||
                                "TONGUE_FOWARD".equals(trainingLabel) ||
                                "TONGUE_BACK".equals(trainingLabel) ||
                                "TONGUE_UP".equals(trainingLabel) ||
                                "TONGUE_DOWN".equals(trainingLabel)) && isYoloEnabled) {
                            // â˜… æ¯ FACE_MESH_EVERY å¹€æ›´æ–°ä¸€æ¬¡ ROIï¼ˆOverlayâ†’Bitmapï¼‰
                            boolean needFaceMesh = (lastOverlayRoi == null) || (frameId % FACE_MESH_EVERY == 0);
                            if (needFaceMesh) {
                                Rect overlayRoi = TongueYoloDetector.calculateMouthROI(allPoints, overlayWidth, overlayHeight);
                                lastOverlayRoi = overlayRoi;

                                float sx = (float) mirroredBitmap.getWidth() / overlayWidth;
                                float sy = (float) mirroredBitmap.getHeight() / overlayHeight;
                                lastBitmapRoi = new Rect(
                                        Math.round(overlayRoi.left * sx),
                                        Math.round(overlayRoi.top * sy),
                                        Math.round(overlayRoi.right * sx),
                                        Math.round(overlayRoi.bottom * sy)
                                );
                            }

                            // æŠŠå¿«å– ROI å‚³çµ¦ YOLOï¼ˆä¸ä¸€å®šæ¯å¹€æ›´æ–° ROIï¼‰
                            handleTongueMode(allPoints, mirroredBitmap, bitmapWidth, bitmapHeight,
                                    lastOverlayRoi, lastBitmapRoi);

                        } else if ("é¼“é °".equals(trainingLabel) ||
                                "PUFF_CHEEK".equals(trainingLabel) ||
                                "REDUCE_CHEEK".equals(trainingLabel)) {
                            // â˜…â˜…â˜… è‡‰é °æ¨¡å¼ï¼šå‘¼å« Farneback å…‰æµå¼•æ“
                            handleCheeksMode(landmarks01, mirroredBitmap);
                        } else if ("ä¸‹é¡".equals(trainingLabel) ||
                                "JAW_LEFT".equals(trainingLabel) ||
                                "JAW_RIGHT".equals(trainingLabel)) {
                            // â˜…â˜…â˜… ä¸‹é¡æ¨¡å¼
                            handleJawMode(allPoints);
                        } else {
                            // å˜´å”‡æ¨¡å¼
                            handleLipMode(allPoints);
                        }

                        // é¼»å°– for åœ“æ¡†ç‹€æ…‹ï¼ˆé¡¯ç¤ºå±¤ç”¨ï¼‰
                        float noseRelativeX = result.faceLandmarks().get(0).get(1).x();
                        float noseRelativeY = result.faceLandmarks().get(0).get(1).y();
                        float noseCorrectedX = (noseRelativeX - 0.5f) * scaleX + 0.5f;

                        float noseScreenX = noseCorrectedX * overlayWidth;
                        float noseScreenY = noseRelativeY * overlayHeight;

                        float centerX = overlayWidth / 2f;
                        float centerY = overlayHeight / 2f;
                        float radius = Math.min(centerX, centerY) - 80;

                        float dx = noseScreenX - centerX;
                        float dy = noseScreenY - centerY;
                        boolean noseInside = (dx * dx + dy * dy) <= (radius * radius);

                        handleFacePosition(noseInside);
                    }
                });

            } catch (Exception e) {
                Log.e(TAG, "æª¢æŸ¥è‡‰éƒ¨ä½ç½®æ™‚ç™¼ç”ŸéŒ¯èª¤", e);
                runOnUiThread(() -> handleFacePosition(false));
            }
        } else {
            runOnUiThread(() -> {
                overlayView.clearAllLandmarks();
                overlayView.clearYoloResults();
                handleFacePosition(false);
                Log.d(TAG, "æœªæª¢æ¸¬åˆ°äººè‡‰");
            });
        }
    }

    /**
     * èˆŒé ­æ¨¡å¼ï¼šç”¨å¿«å–å¥½çš„ ROI + ç¯€æµ YOLO
     */
    private void handleTongueMode(float[][] allPoints,
                                  Bitmap mirroredBitmap,
                                  int bitmapWidth,
                                  int bitmapHeight,
                                  Rect overlayRoi,   // â† ä½¿ç”¨å¿«å– Overlay ROI
                                  Rect bitmapRoi) {  // â† ä½¿ç”¨å¿«å– Bitmap ROI
        try {
            if (!shouldAcceptNewFrames()) return;
            // â˜… æ¯ YOLO_EVERY å¹€è·‘ä¸€æ¬¡ YOLO
            if ((frameId % YOLO_EVERY) != 0) return;
            if (overlayRoi == null || bitmapRoi == null) return;

            int overlayWidth = overlayView.getWidth();
            int overlayHeight = overlayView.getHeight();

            final Rect mouthROIFinal = new Rect(overlayRoi);
            final float[][] allPointsFinal = allPoints;
            final Rect bitmapROIFinal = new Rect(bitmapRoi);

            yoloExecutor.execute(() -> {
                long t0 = System.nanoTime();
                TongueYoloDetector.DetectionResult result =
                        tongueDetector.detectTongueWithRealPosition(
                                mirroredBitmap, bitmapROIFinal, overlayWidth, overlayHeight);
                long t1 = System.nanoTime();
                float inferMs = (t1 - t0) / 1_000_000f;

                Rect viewTongueBox = null;
                if (result.detected && result.boundingBox != null) {
                    float sx = overlayWidth  / (float) mirroredBitmap.getWidth();
                    float sy = overlayHeight / (float) mirroredBitmap.getHeight();
                    Rect b = result.boundingBox;
                    viewTongueBox = new Rect(
                            Math.round(b.left   * sx),
                            Math.round(b.top    * sy),
                            Math.round(b.right  * sx),
                            Math.round(b.bottom * sy)
                    );
                }

                // æ¯ 10 ç§’æ‰“ä¸€è¡Œ METRICS
                String thermalStr = "N/A";
                try {
                    android.os.PowerManager pm = (android.os.PowerManager) getSystemService(POWER_SERVICE);
                    if (pm != null) {
                        int ts = pm.getCurrentThermalStatus();
                        switch (ts) {
                            case android.os.PowerManager.THERMAL_STATUS_NONE:      thermalStr = "NONE"; break;
                            case android.os.PowerManager.THERMAL_STATUS_LIGHT:     thermalStr = "LIGHT"; break;
                            case android.os.PowerManager.THERMAL_STATUS_MODERATE:  thermalStr = "MODERATE"; break;
                            case android.os.PowerManager.THERMAL_STATUS_SEVERE:    thermalStr = "SEVERE"; break;
                            case android.os.PowerManager.THERMAL_STATUS_CRITICAL:  thermalStr = "CRITICAL"; break;
                            case android.os.PowerManager.THERMAL_STATUS_EMERGENCY: thermalStr = "EMERGENCY"; break;
                            case android.os.PowerManager.THERMAL_STATUS_SHUTDOWN:  thermalStr = "SHUTDOWN"; break;
                            default: thermalStr = String.valueOf(ts);
                        }
                    }
                } catch (Throwable ignore) {}

                long now = System.currentTimeMillis();
                if (firstMetricTime == 0) firstMetricTime = now;
                long elapsed = (now - firstMetricTime) / 1000;
                if (elapsed == 10 || elapsed == 20 || elapsed == 30 || elapsed == 40) {
                    Log.d(TAG, String.format("METRICS@%ds infer=%.1fms bestProb=%.3f thermal=%s",
                            elapsed, inferMs, result.confidence, thermalStr));
                }

                Rect finalViewTongueBox = viewTongueBox;
                //æº–å‚™å¸¶å…¥ä¸»åŸ·è¡Œç·’
                final boolean detected = result.detected;
                final float conf = result.confidence;
                final Rect bboxImgFinal = (result.detected && result.boundingBox != null)
                        ? new Rect(result.boundingBox) : null;
                mainHandler.post(() -> {
                    overlayView.setYoloDetectionResult(detected, conf, finalViewTongueBox, mouthROIFinal);

                    if (!isTrainingCompleted && (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)) {
                        String stateString = (currentState == AppState.CALIBRATING) ? "CALIBRATING" : "MAINTAINING";

                        // 1) å½±åƒå°ºå¯¸ï¼ˆBitmap åƒç´ ï¼‰
                        final int imgW = mirroredBitmap.getWidth();
                        final int imgH = mirroredBitmap.getHeight();

                        // 2) YOLO bboxï¼ˆBitmap åƒç´ ï¼›ç„¡åµæ¸¬â†’nullï¼‰
                        final android.graphics.Rect bboxImg = bboxImgFinal;

                        // 3) å°‡ allPointsFinal çµ±ä¸€åˆ°ã€ŒBitmap åƒç´ ã€
                        float[][] ptsPx = toBitmapPixels(allPointsFinal, imgW, imgH, overlayView.getWidth(), overlayView.getHeight());

                        // 4) å–éœ€è¦çš„è‡‰éƒ¨é»ï¼ˆMediaPipe FaceMesh indexï¼‰
                        final int EYE_R = 33, EYE_L = 263, BROW_C = 168, NOSE_T = 1;
                        float eyeRx = ptsPx[EYE_R][0], eyeRy = ptsPx[EYE_R][1];
                        float eyeLx = ptsPx[EYE_L][0], eyeLy = ptsPx[EYE_L][1];
                        float browCx = ptsPx[BROW_C][0],  browCy = ptsPx[BROW_C][1];
                        float noseX  = ptsPx[NOSE_T][0],  noseY  = ptsPx[NOSE_T][1];

                        // 5) è£œæ­£åƒæ•¸ï¼šåŸé»ï¼ˆä½ è¦çš„åŸºæº–é»ï¼‰ï¼Œæ—‹è½‰è§’ï¼ˆå…©çœ¼ç·šï¼‰ã€ç¸®æ”¾ï¼ˆå…©çœ¼è·ï¼‰
                        float originX = noseX, originY = noseY;   // ä½ è¦ç”¨é¼»å°–ç•¶åŸé»
                        float vxEye = eyeRx - eyeLx, vyEye = eyeRy - eyeLy;
                        float dio   = (float) Math.hypot(vxEye, vyEye);       // å…©çœ¼è·
                        float theta = (float) Math.atan2(vyEye, vxEye);       // å…©çœ¼ç·šç›¸å°æ°´å¹³è§’ï¼ˆå¼§åº¦ï¼‰

                        // 6) èˆŒé ­ä¸­å¿ƒï¼ˆBitmap åƒç´ ï¼‰èˆ‡è£œæ­£å¾Œåº§æ¨™
                        float cxImg = Float.NaN, cyImg = Float.NaN, xNorm = Float.NaN, yNorm = Float.NaN;
                        if (bboxImg != null) {
                            cxImg = (bboxImg.left + bboxImg.right) * 0.5f;
                            cyImg = (bboxImg.top  + bboxImg.bottom) * 0.5f;

                            // å¹³ç§»åˆ°åŸé»
                            float vx = cxImg - originX;
                            float vy = cyImg - originY;

                            // æ—‹è½‰ -thetaï¼ˆè®“å…©çœ¼ç·šæ°´å¹³ï¼‰
                            float cosT = (float) Math.cos(theta), sinT = (float) Math.sin(theta);
                            float xr =  vx * cosT + vy * sinT;
                            float yr = -vx * sinT + vy * cosT;

                            // ç¸®æ”¾æ­£è¦åŒ–ï¼ˆé™¤ä»¥å…©çœ¼è·ï¼‰
                            if (dio > 1e-3f) {
                                xNorm = xr / dio;
                                yNorm = yr / dio;
                            }
                        }

                        // 7) å¯«å…¥ï¼šå‘¼å«ã€ŒèˆŒé ­å°ˆç”¨å¤šè¼‰ã€
                        dataRecorder.recordLandmarkData(
                                stateString,
                                detected,
                                bboxImg,
                                eyeLx, eyeLy, eyeRx, eyeRy,
                                browCx, browCy, noseX, noseY,
                                imgW, imgH,
                                System.currentTimeMillis(),
                                originX, originY,
                                theta,
                                dio,
                                cxImg, cyImg,
                                xNorm, yNorm
                        );
                    }
                });

                /*
                mainHandler.post(() -> {
                    overlayView.setYoloDetectionResult(detected, conf, finalViewTongueBox, mouthROIFinal);
                    if (!isTrainingCompleted && (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)) {
                        String stateString = (currentState == AppState.CALIBRATING) ? "CALIBRATING" : "MAINTAINING";
                        dataRecorder.recordLandmarkData(stateString, allPointsFinal, detected);
                    }
                });*/
            });

        } catch (Exception e) {
            Log.e(TAG, "è™•ç†èˆŒé ­æ¨¡å¼æ™‚ç™¼ç”ŸéŒ¯èª¤", e);

            /*
            if (!isTrainingCompleted && (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)) {
                String stateString = (currentState == AppState.CALIBRATING) ? "CALIBRATING" : "MAINTAINING";
                dataRecorder.recordLandmarkData(stateString, allPoints, false);
            }*/
        }
    }

    // å˜´å”‡æ¨¡å¼ï¼šMediaPipe é—œéµé»
    private void handleLipMode(float[][] allPoints) {
        if (!shouldAcceptNewFrames()) return;
        overlayView.setAllFaceLandmarks(allPoints);

        if (!isTrainingCompleted && (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)) {
            String stateString = (currentState == AppState.CALIBRATING) ? "CALIBRATING" : "MAINTAINING";
            dataRecorder.recordLandmarkData(stateString, allPoints, null);
            Log.d(TAG, "è¨˜éŒ„å˜´å”‡è³‡æ–™: " + stateString + ", é—œéµé»æ•¸é‡: " + allPoints.length);
        }
    }

    // ä¸‹é¡æ¨¡å¼ï¼šMediaPipe é—œéµé»
    private void handleJawMode(float[][] allPoints) {
        if (!shouldAcceptNewFrames()) return;
        overlayView.setAllFaceLandmarks(allPoints);

        if (!isTrainingCompleted && (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING)) {
            String stateString = (currentState == AppState.CALIBRATING) ? "CALIBRATING" : "MAINTAINING";
            dataRecorder.recordLandmarkData(stateString, allPoints, true);
            Log.d(TAG, "è¨˜ä¸‹é¡è³‡æ–™: " + stateString + ", é—œéµé»æ•¸é‡: " + allPoints.length);
        }
    }

    private void handleFacePosition(boolean faceInside) {
        if (isTrainingCompleted) return;

        long currentTime = System.currentTimeMillis();

        switch (currentState) {
            case CALIBRATING:
                if (faceInside) {
                    if (calibrationStartTime == 0) {
                        calibrationStartTime = currentTime;
                        startCalibrationTimer();
                    }
                    overlayView.setStatus(CircleOverlayView.Status.CALIBRATING);
                } else {
                    resetCalibration();
                    overlayView.setStatus(CircleOverlayView.Status.OUT_OF_BOUND);
                    currentState = AppState.OUT_OF_BOUNDS;
                }
                break;

            case MAINTAINING:
                if (faceInside) {
                    if (maintainStartTime == 0) {
                        maintainStartTime = currentTime;
                    }
                    overlayView.setStatus(CircleOverlayView.Status.OK);
                } else {
                    if (maintainStartTime > 0) {
                        maintainTotalTime += (currentTime - maintainStartTime);
                        maintainStartTime = 0;
                    }
                    resetToCalibration();
                }
                break;

            case OUT_OF_BOUNDS:
                if (faceInside) {
                    resetToCalibration();
                } else {
                    overlayView.setStatus(CircleOverlayView.Status.OUT_OF_BOUND);
                }
                break;
        }

        updateStatusDisplay();
        updateTimerDisplay();
    }

    //è‡‰é °æ¨¡å¼
    private void handleCheeksMode(float[][] landmarks01, Bitmap mirroredBitmap) {
        if (!shouldAcceptNewFrames()) return;
        try {
            ensureCheekEngine();
            long ts = System.currentTimeMillis();

            cameraExecutor.execute(() -> {
                CheekFlowEngine.FlowResult r = cheekEngine.process(mirroredBitmap, landmarks01, ts);

                if (!isTrainingCompleted &&
                        (currentState == AppState.CALIBRATING || currentState == AppState.MAINTAINING) &&
                        r.computedThisFrame) {
                    //è£œå„Ÿ
                    org.opencv.core.Point li = r.vectors.get(CheekFlowEngine.Region.LEFT_INNER);
                    org.opencv.core.Point ri = r.vectors.get(CheekFlowEngine.Region.RIGHT_INNER);
                    //åŸå§‹
                    org.opencv.core.Point liRaw = r.rawVectors.get(CheekFlowEngine.Region.LEFT_INNER);
                    org.opencv.core.Point riRaw = r.rawVectors.get(CheekFlowEngine.Region.RIGHT_INNER);
                    // å–å¾—ç‹€æ…‹å­—ä¸²ï¼ˆè·Ÿä½ å˜´å”‡/èˆŒé ­ä¸€è‡´ï¼‰
                    String stateString = (currentState == AppState.CALIBRATING) ? "CALIBRATING" : "MAINTAINING";

                    // âœ… æ”¹æˆå¯«é€²ä¸» CSVï¼ˆè‡‰é °è¡¨é ­ï¼‰
                    dataRecorder.recordLandmarkData(
                            stateString,
                            (float) li.x, (float) li.y,
                            (float) ri.x, (float) ri.y,
                            (float) liRaw.x, (float) liRaw.y,
                            (float) riRaw.x, (float) riRaw.y
                    );

                    // ï¼ˆå¯é¸ï¼‰overlay è¦–è¦ºåŒ–
                    // mainHandler.post(() -> overlayView.setCheekVectors(
                    //      new CircleOverlayView.Vector2((float) li.x, (float) li.y),
                    //      new CircleOverlayView.Vector2((float) ri.x, (float) ri.y)
                    // ));
                }
            });

        } catch (Exception e) {
            Log.e(TAG, "handleCheeksMode error", e);
        }
    }


    private void startCalibrationTimer() {
        cancelTimers();
        Log.d(TAG, "ğŸŸ¡ é–‹å§‹æ ¡æ­£éšæ®µè¨ˆæ™‚å™¨");

        calibrationTimer = () -> {
            Log.d(TAG, "ğŸŸ¡ æ ¡æ­£å®Œæˆï¼Œåˆ‡æ›åˆ°ç¶­æŒç‹€æ…‹");
            currentState = AppState.MAINTAINING;
            maintainStartTime = System.currentTimeMillis();
            overlayView.setStatus(CircleOverlayView.Status.OK);
            startMaintainTimer();
            updateStatusDisplay();
            updateTimerDisplay();
        };
        mainHandler.postDelayed(calibrationTimer, CALIBRATION_TIME);
    }

    private void startMaintainTimer() {
        cancelTimers();
        Log.d(TAG, "ğŸŸ¢ é–‹å§‹ç¶­æŒéšæ®µè¨ˆæ™‚å™¨");

        maintainTimer = () -> {
            long currentTime = System.currentTimeMillis();
            long currentMaintainTime = maintainTotalTime;
            if (maintainStartTime > 0) {
                currentMaintainTime += (currentTime - maintainStartTime);
            }

            if (currentMaintainTime % 5000 < 100) {
                Log.d(TAG, String.format("â±ï¸ ç¶­æŒè¨ˆæ™‚æª¢æŸ¥ - ç´¯è¨ˆæ™‚é–“: %d ms / %d ms (%.1f%%)",
                        currentMaintainTime, MAINTAIN_TIME_TOTAL,
                        (currentMaintainTime * 100.0 / MAINTAIN_TIME_TOTAL)));
            }

            if (currentMaintainTime >= MAINTAIN_TIME_TOTAL) {
                Log.d(TAG, "âœ… ç¶­æŒæ™‚é–“é”æ¨™ï¼è¨“ç·´å®Œæˆ");
                completedTraining();
            } else {
                mainHandler.postDelayed(maintainTimer, 100);
            }
        };
        mainHandler.postDelayed(maintainTimer, 100);
    }

    private void startProgressUpdater() {
        progressUpdater = () -> {
            updateProgressBar();
            mainHandler.postDelayed(progressUpdater, PROGRESS_UPDATE_INTERVAL);
        };
        mainHandler.post(progressUpdater);
    }

    private void updateProgressBar() {
        if (isTrainingCompleted) {
            progressBar.setProgress(100);
            return;
        }

        int progress = 0;
        long currentTime = System.currentTimeMillis();

        switch (currentState) {
            case CALIBRATING:
                if (calibrationStartTime > 0) {
                    long elapsed = currentTime - calibrationStartTime;
                    progress = (int) ((elapsed * 100) / CALIBRATION_TIME);
                    progress = Math.min(progress, 100);
                }
                break;

            case MAINTAINING:
                long totalMaintainTime = maintainTotalTime;
                if (maintainStartTime > 0) {
                    totalMaintainTime += (currentTime - maintainStartTime);
                }
                progress = (int) ((totalMaintainTime * 100) / MAINTAIN_TIME_TOTAL);
                progress = Math.min(progress, 100);
                break;

            case OUT_OF_BOUNDS:
                break;
        }

        progressBar.setProgress(progress);
    }

    private void resetCalibration() {
        if (!isTrainingCompleted) {
            calibrationStartTime = 0;
            cancelTimers();
            currentState = AppState.CALIBRATING;
        }
    }

    private void resetToCalibration() {
        if (!isTrainingCompleted) {
            calibrationStartTime = 0;
            maintainStartTime = 0;
            cancelTimers();
            currentState = AppState.CALIBRATING;
        }
    }

    private void cancelTimers() {
        if (calibrationTimer != null) {
            mainHandler.removeCallbacks(calibrationTimer);
            calibrationTimer = null;
        }
        if (maintainTimer != null) {
            mainHandler.removeCallbacks(maintainTimer);
            maintainTimer = null;
        }
    }

    private void completedTraining() {
        Log.d(TAG, "ğŸ‰ğŸ‰ğŸ‰ === è¨“ç·´å®Œæˆï¼é–‹å§‹å„²å­˜è³‡æ–™ === ğŸ‰ğŸ‰ğŸ‰");
        isTrainingCompleted = true;
        cancelTimers();

        overlayView.setStatus(CircleOverlayView.Status.OK);
        updateStatusDisplay();
        updateTimerDisplay();

        Toast.makeText(this, "ğŸ‰ è¨“ç·´å®Œæˆï¼\næ­£åœ¨å„²å­˜æª”æ¡ˆä¸¦é€²è¡Œå³°å€¼åˆ†æ...", Toast.LENGTH_LONG).show();

        dataRecorder.saveToFileWithCallback(new FaceDataRecorder.DataSaveCallback() {
            @Override
            public void onComplete(CSVPeakAnalyzer.AnalysisResult result) {
                Log.d(TAG, "âœ… å„²å­˜èˆ‡åˆ†æå®Œæˆï¼Œæº–å‚™è·³è½‰çµæœé é¢");
                Log.d(TAG, String.format("ğŸ“Š åˆ†æçµæœ - ç¸½å³°å€¼: %d", result.totalPeaks));
                Intent intent = new Intent(FaceCircleCheckerActivity.this, AnalysisResultActivity.class);
                intent.putExtra("training_label", trainingLabel);
                intent.putExtra("actual_count", result.totalPeaks);
                intent.putExtra("target_count", 4);
                intent.putExtra("training_duration", MAINTAIN_TIME_TOTAL / 1000);
                intent.putExtra("csv_file_name", dataRecorder.getFileName());
                startActivity(intent);
                finish();
            }

            @Override
            public void onError(String error) {
                Log.e(TAG, "âŒ å„²å­˜æˆ–åˆ†æå¤±æ•—: " + error);
                Toast.makeText(FaceCircleCheckerActivity.this, "è™•ç†å¤±æ•—: " + error, Toast.LENGTH_LONG).show();
                new Handler(Looper.getMainLooper()).postDelayed(() -> finish(), 3000);
            }
        });
    }

    private void updateStatusDisplay() {
        if (statusText == null) return;

        String text;
        if (isTrainingCompleted) {
            text = "âœ… è¨“ç·´å®Œæˆï¼\næ­£åœ¨é€²è¡Œå³°å€¼åˆ†æ...";
        } else {
            switch (currentState) {
                case CALIBRATING:
                    text = "æ ¡æ­£ä¸­\nè«‹æ­£å°é¡é ­ï¼Œä¸¦ä¿æŒé¼»å°–åœ¨åœ“æ¡†å…§5ç§’";
                    break;
                case MAINTAINING:
                    text = trainingLabel + "\nè«‹ç¶­æŒ30ç§’";
                    break;
                case OUT_OF_BOUNDS:
                default:
                    text = "åµæ¸¬åˆ°è‡‰éƒ¨è¶…å‡ºå€åŸŸ\nè«‹è®“é¼»å°–å›åˆ°åœ“æ¡†å…§ï¼Œé‡æ–°æ ¡æ­£";
                    break;
            }
        }
        statusText.setText(text);
    }

    private void updateTimerDisplay() {
        if (timerText == null) return;

        if (isTrainingCompleted) {
            timerText.setText("âœ… å®Œæˆ");
            return;
        }

        long currentTime = System.currentTimeMillis();
        String timeText;

        switch (currentState) {
            case CALIBRATING:
                if (calibrationStartTime > 0) {
                    long elapsed = currentTime - calibrationStartTime;
                    long remaining = Math.max(0, CALIBRATION_TIME - elapsed);
                    timeText = String.format("â± %dç§’", (remaining / 1000) + 1);
                } else {
                    timeText = "â± 5ç§’";
                }
                break;

            case MAINTAINING:
                long totalMaintainTime = maintainTotalTime;
                if (maintainStartTime > 0) {
                    totalMaintainTime += (currentTime - maintainStartTime);
                }
                long remaining = Math.max(0, MAINTAIN_TIME_TOTAL - totalMaintainTime);
                timeText = String.format("â± %dç§’", remaining / 1000);
                break;

            case OUT_OF_BOUNDS:
            default:
                timeText = "â± --";
                break;
        }

        timerText.setText(timeText);
    }

    // å¹«æ‰‹ï¼šé—œé–‰ ExecutorServiceï¼ˆå¯é‡ç”¨ï¼‰
    private void awaitShutdown(java.util.concurrent.ExecutorService exec) {
        if (exec == null) return;
        try {
            exec.shutdownNow(); // ç«‹åˆ»ä¸­æ–·å°šæœªé–‹å§‹çš„èˆ‡å¯ä¸­æ–·çš„ä»»å‹™
            exec.awaitTermination(1500, java.util.concurrent.TimeUnit.MILLISECONDS); // ç­‰ä¸€ä¸‹æ”¶å°¾
        } catch (InterruptedException ignored) {
        }
    }
    @Override
    protected void onDestroy() {
        super.onDestroy();

        // 1) åœå…¥å£ï¼šä¹‹å¾Œä¸è¦å†æäº¤ä»»ä½•æ–°ä»»å‹™
        isStopping = true;

        // 2) å…ˆæŠŠ UI/Timer callback åœæ‰ï¼Œé¿å…åˆæ’æ–°ä»»å‹™
        cancelTimers();
        if (progressUpdater != null) {
            mainHandler.removeCallbacks(progressUpdater);
            progressUpdater = null;
        }

        // 3) å…ˆåœç›¸æ©Ÿè³‡æ–™æºï¼Œé¿å…é‚„æœ‰æ–°å½±æ ¼æ¹§å…¥ï¼ˆå¾ˆé—œéµï¼‰
        try {
            if (cameraProvider != null) {
                cameraProvider.unbindAll();
            }
        } catch (Exception ignore) { }

        // 4) åœæ‰èƒŒæ™¯åŸ·è¡Œç·’ä¸¦ã€Œç­‰å®ƒåœä¹¾æ·¨ã€
        awaitShutdown(cameraExecutor);
        awaitShutdown(yoloExecutor);

        // 5) åŸ·è¡Œç·’éƒ½åœäº†ï¼Œç¾åœ¨æ‰å®‰å…¨é‡‹æ”¾å„å¼•æ“/åµæ¸¬å™¨
        if (cheekEngine != null) {
            try {
                cheekEngine.release();
            } catch (Throwable ignore) { }
            cheekEngine = null;
        }

        if (tongueDetector != null) {
            try {
                tongueDetector.release();
            } catch (Throwable ignore) { }
            tongueDetector = null;
            Log.d(TAG, "âœ… YOLO æª¢æ¸¬å™¨è³‡æºå·²æ¸…ç†");
        }

        if (faceLandmarker != null) {
            try {
                faceLandmarker.close();
            } catch (Throwable ignore) { }
            faceLandmarker = null;
        }

        // 6) åƒè¬ä¸è¦åœ¨ onDestroy æ¸… CSVï¼Œå¦å‰‡çµæœé æœƒæ‹¿åˆ°ç©ºè³‡æ–™
        // if (dataRecorder != null) { dataRecorder.clearData(); }  // â† ç§»é™¤é€™è¡Œ
    }


    private void testCameraPermission() {
        Log.d(TAG, "é–‹å§‹æª¢æŸ¥ç›¸æ©Ÿæ¬Šé™");
        int cameraPermission = ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA);
        Log.d(TAG, "ç›¸æ©Ÿæ¬Šé™ç‹€æ…‹: " + cameraPermission);
        Log.d(TAG, "PERMISSION_GRANTED å¸¸æ•¸: " + PackageManager.PERMISSION_GRANTED);
        Log.d(TAG, "PERMISSION_DENIED å¸¸æ•¸: " + PackageManager.PERMISSION_DENIED);

        PackageManager pm = getPackageManager();
        boolean hasCamera = pm.hasSystemFeature(PackageManager.FEATURE_CAMERA);
        boolean hasFrontCamera = pm.hasSystemFeature(PackageManager.FEATURE_CAMERA_FRONT);

        Log.d(TAG, "ç³»çµ±æ”¯æ´ç›¸æ©Ÿ: " + hasCamera);
        Log.d(TAG, "ç³»çµ±æ”¯æ´å‰ç½®ç›¸æ©Ÿ: " + hasFrontCamera);
    }
}
